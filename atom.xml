<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>机器学习杂货铺总店</title>
  <icon>https://fesianxu.github.io/icon.png</icon>
  
  <link href="https://fesianxu.github.io/atom.xml" rel="self"/>
  
  <link href="https://fesianxu.github.io/"/>
  <updated>2025-09-13T02:04:49.475Z</updated>
  <id>https://fesianxu.github.io/</id>
  
  <author>
    <name>FesianXu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>视觉大语言模型未能充分利用视觉表征</title>
    <link href="https://fesianxu.github.io/2025/09/13/vlm-overlook-visual-repr-20250913/"/>
    <id>https://fesianxu.github.io/2025/09/13/vlm-overlook-visual-repr-20250913/</id>
    <published>2025-09-13T02:00:22.000Z</published>
    <updated>2025-09-13T02:04:49.475Z</updated>
    
    
    <summary type="html">&lt;p&gt;这两天看到一篇新挂在arxiv上的文章
[1]，讨论了下视觉大语言模型的视觉表征退化问题。先前的研究将VLM缺陷归咎于视觉编码器薄弱，并提出集成编码器方案以弥补不足，本文认为可能是底座LLM不能充分利用视觉编码器的特征...&lt;/p&gt;</summary>
    
    
    
    <category term="计算机视觉" scheme="https://fesianxu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
    <category term="多视角视觉" scheme="https://fesianxu.github.io/tags/%E5%A4%9A%E8%A7%86%E8%A7%92%E8%A7%86%E8%A7%89/"/>
    
    <category term="计算机视觉" scheme="https://fesianxu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    <category term="多视角几何" scheme="https://fesianxu.github.io/tags/%E5%A4%9A%E8%A7%86%E8%A7%92%E5%87%A0%E4%BD%95/"/>
    
    <category term="圆锥线" scheme="https://fesianxu.github.io/tags/%E5%9C%86%E9%94%A5%E7%BA%BF/"/>
    
    <category term="二次圆锥面" scheme="https://fesianxu.github.io/tags/%E4%BA%8C%E6%AC%A1%E5%9C%86%E9%94%A5%E9%9D%A2/"/>
    
  </entry>
  
  <entry>
    <title>大模型偏好对齐中的DPO和PPO方法</title>
    <link href="https://fesianxu.github.io/2025/09/13/dpo-and-ppo-in-llm-20250913/"/>
    <id>https://fesianxu.github.io/2025/09/13/dpo-and-ppo-in-llm-20250913/</id>
    <published>2025-09-13T01:48:43.000Z</published>
    <updated>2025-09-13T02:29:51.333Z</updated>
    
    
    <summary type="html">&lt;p&gt;也许一文能够看懂的DPO和PPO方法...&lt;/p&gt;</summary>
    
    
    
    <category term="大模型后训练" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83/"/>
    
    
    <category term="偏好对齐" scheme="https://fesianxu.github.io/tags/%E5%81%8F%E5%A5%BD%E5%AF%B9%E9%BD%90/"/>
    
    <category term="大模型后训练" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83/"/>
    
    <category term="DPO" scheme="https://fesianxu.github.io/tags/DPO/"/>
    
    <category term="PPO" scheme="https://fesianxu.github.io/tags/PPO/"/>
    
    <category term="大模型中的RL方法" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84RL%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>BoNBoN——结合行为模仿和偏好对齐进行Best-of-N对齐的方法</title>
    <link href="https://fesianxu.github.io/2025/03/24/bonbon-20250324/"/>
    <id>https://fesianxu.github.io/2025/03/24/bonbon-20250324/</id>
    <published>2025-03-24T08:02:11.000Z</published>
    <updated>2025-03-24T16:08:40.718Z</updated>
    
    
    <summary type="html">&lt;p&gt;BoNBoN结合了行为模仿和偏好对齐，在模型的Best-of-N结果基础上进行对齐...&lt;/p&gt;</summary>
    
    
    
    <category term="大模型" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="大模型" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="Best-of-N" scheme="https://fesianxu.github.io/tags/Best-of-N/"/>
    
    <category term="偏好对齐" scheme="https://fesianxu.github.io/tags/%E5%81%8F%E5%A5%BD%E5%AF%B9%E9%BD%90/"/>
    
    <category term="行为模仿" scheme="https://fesianxu.github.io/tags/%E8%A1%8C%E4%B8%BA%E6%A8%A1%E4%BB%BF/"/>
    
  </entry>
  
  <entry>
    <title>给定计算预算下的最佳LLM模型尺寸与预训练数据量分配</title>
    <link href="https://fesianxu.github.io/2025/03/14/compute-optimal-llm-20250314/"/>
    <id>https://fesianxu.github.io/2025/03/14/compute-optimal-llm-20250314/</id>
    <published>2025-03-14T00:37:52.000Z</published>
    <updated>2025-03-14T00:42:23.467Z</updated>
    
    
    <summary type="html">&lt;p&gt;如果给定了计算预算C，如何分配LLM的模型尺寸N和训练的数据量D，才能使得模型的效果L最好呢...&lt;/p&gt;</summary>
    
    
    
    <category term="大规模语言模型" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="LLM" scheme="https://fesianxu.github.io/tags/LLM/"/>
    
    <category term="最佳计算预算分配" scheme="https://fesianxu.github.io/tags/%E6%9C%80%E4%BD%B3%E8%AE%A1%E7%AE%97%E9%A2%84%E7%AE%97%E5%88%86%E9%85%8D/"/>
    
    <category term="最佳模型尺寸" scheme="https://fesianxu.github.io/tags/%E6%9C%80%E4%BD%B3%E6%A8%A1%E5%9E%8B%E5%B0%BA%E5%AF%B8/"/>
    
    <category term="最佳预训练数据量" scheme="https://fesianxu.github.io/tags/%E6%9C%80%E4%BD%B3%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>大模型推理时的尺度扩展定律</title>
    <link href="https://fesianxu.github.io/2025/03/02/test-time-scaling-laws-20250302/"/>
    <id>https://fesianxu.github.io/2025/03/02/test-time-scaling-laws-20250302/</id>
    <published>2025-03-02T14:25:12.000Z</published>
    <updated>2025-03-02T14:32:30.505Z</updated>
    
    
    <summary type="html">&lt;p&gt;大模型的尺度扩展定律告诉我们：『LLM的性能会随着模型的参数量、模型的训练量、模型的训练数据量的增加而增加』。训练存在尺度扩展定律，测试也存在尺度扩展定律，实践告诉我们在推理时候增大计算量，往往可以获得模型性能收益。那么在给定了计算预算的前提下，如何安排预算才能达到最好的模型效果呢？&lt;/p&gt;</summary>
    
    
    
    <category term="大规模语言模型" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="大语言模型" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="测试时尺度扩展" scheme="https://fesianxu.github.io/tags/%E6%B5%8B%E8%AF%95%E6%97%B6%E5%B0%BA%E5%BA%A6%E6%89%A9%E5%B1%95/"/>
    
    <category term="Scaling Laws" scheme="https://fesianxu.github.io/tags/Scaling-Laws/"/>
    
  </entry>
  
  <entry>
    <title>世界多胞体与世界模型</title>
    <link href="https://fesianxu.github.io/2025/02/09/world-model-polytope/"/>
    <id>https://fesianxu.github.io/2025/02/09/world-model-polytope/</id>
    <published>2025-02-09T14:51:58.000Z</published>
    <updated>2025-02-09T14:53:54.386Z</updated>
    
    
    <summary type="html">&lt;p&gt;本文记一下我的一个胡思乱想，也不知道有没有现有的论文去研究这个东西，有空我去看看...&lt;/p&gt;</summary>
    
    
    
    <category term="世界模型" scheme="https://fesianxu.github.io/categories/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="世界模型" scheme="https://fesianxu.github.io/tags/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="世界多胞体" scheme="https://fesianxu.github.io/tags/%E4%B8%96%E7%95%8C%E5%A4%9A%E8%83%9E%E4%BD%93/"/>
    
  </entry>
  
  <entry>
    <title>从一个例子开始，理解互联网岗位分工</title>
    <link href="https://fesianxu.github.io/2025/02/09/internet-work-20250209/"/>
    <id>https://fesianxu.github.io/2025/02/09/internet-work-20250209/</id>
    <published>2025-02-09T14:47:38.000Z</published>
    <updated>2025-02-09T14:51:23.920Z</updated>
    
    
    <summary type="html">&lt;p&gt;你我皆牛马，活在网中间~&lt;/p&gt;</summary>
    
    
    
    <category term="互联网趣闻" scheme="https://fesianxu.github.io/categories/%E4%BA%92%E8%81%94%E7%BD%91%E8%B6%A3%E9%97%BB/"/>
    
    
    <category term="互联网工作" scheme="https://fesianxu.github.io/tags/%E4%BA%92%E8%81%94%E7%BD%91%E5%B7%A5%E4%BD%9C/"/>
    
    <category term="大厂" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E5%8E%82/"/>
    
    <category term="岗位分工" scheme="https://fesianxu.github.io/tags/%E5%B2%97%E4%BD%8D%E5%88%86%E5%B7%A5/"/>
    
    <category term="产品设计" scheme="https://fesianxu.github.io/tags/%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="见闻录" scheme="https://fesianxu.github.io/tags/%E8%A7%81%E9%97%BB%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>奖励模型中的尺度扩展定律和奖励劫持</title>
    <link href="https://fesianxu.github.io/2025/02/09/scaling-law-in-reward-model-20250209/"/>
    <id>https://fesianxu.github.io/2025/02/09/scaling-law-in-reward-model-20250209/</id>
    <published>2025-02-09T01:18:49.000Z</published>
    <updated>2025-02-09T02:00:29.741Z</updated>
    
    
    <summary type="html">&lt;p&gt;奖励模型（Reward Model）中的尺度扩展规律（Scaling
Laws），也即是通过扩展奖励模型的模型大小、数据量等去提升奖励模型的能力...&lt;/p&gt;</summary>
    
    
    
    <category term="大模型后训练" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83/"/>
    
    
    <category term="大模型" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="偏好对齐" scheme="https://fesianxu.github.io/tags/%E5%81%8F%E5%A5%BD%E5%AF%B9%E9%BD%90/"/>
    
    <category term="奖励模型" scheme="https://fesianxu.github.io/tags/%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="奖励劫持" scheme="https://fesianxu.github.io/tags/%E5%A5%96%E5%8A%B1%E5%8A%AB%E6%8C%81/"/>
    
    <category term="尺度扩展定律" scheme="https://fesianxu.github.io/tags/%E5%B0%BA%E5%BA%A6%E6%89%A9%E5%B1%95%E5%AE%9A%E5%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>MeCO——给预训练数据增加源信息,就能减少33%的训练量并且提升效果</title>
    <link href="https://fesianxu.github.io/2025/01/11/MeCo-20250111/"/>
    <id>https://fesianxu.github.io/2025/01/11/MeCo-20250111/</id>
    <published>2025-01-11T03:21:32.000Z</published>
    <updated>2025-01-11T03:27:29.363Z</updated>
    
    
    <summary type="html">&lt;p&gt;最近看到一篇预训练的文章，只在每条预训练数据的前面加上一个源信息（即是该信息的URL信息），就能加速训练（+33%）并且提升下游任务的效果...&lt;/p&gt;</summary>
    
    
    
    <category term="大模型预训练" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    
    
    <category term="大模型预训练" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    
    <category term="源信息" scheme="https://fesianxu.github.io/tags/%E6%BA%90%E4%BF%A1%E6%81%AF/"/>
    
  </entry>
  
  <entry>
    <title>DoReMi——一种通过代理模型估计大模型预训练最佳数据配比的方法</title>
    <link href="https://fesianxu.github.io/2025/01/05/doremi-llm-pretrain-20250105/"/>
    <id>https://fesianxu.github.io/2025/01/05/doremi-llm-pretrain-20250105/</id>
    <published>2025-01-05T15:31:00.000Z</published>
    <updated>2025-01-05T16:00:50.862Z</updated>
    
    
    <summary type="html">&lt;p&gt;LLM的预训练是决定其底座能力的至关重要的步骤，其预训练数据通常会包含有多种领域的数据，如何调整不同领域的数据配比（可以理解为采样频率）是极其重要的大模型预训练研究点...&lt;/p&gt;</summary>
    
    
    
    <category term="大模型预训练" scheme="https://fesianxu.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    
    
    <category term="大模型预训练" scheme="https://fesianxu.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    
    <category term="LLM预训练数据配比" scheme="https://fesianxu.github.io/tags/LLM%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94/"/>
    
    <category term="代理模型" scheme="https://fesianxu.github.io/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="最佳数据配比" scheme="https://fesianxu.github.io/tags/%E6%9C%80%E4%BD%B3%E6%95%B0%E6%8D%AE%E9%85%8D%E6%AF%94/"/>
    
  </entry>
  
  <entry>
    <title>基于shell的简单好用多进程wrapper</title>
    <link href="https://fesianxu.github.io/2024/12/21/shell-multiprocess-worker-20241221/"/>
    <id>https://fesianxu.github.io/2024/12/21/shell-multiprocess-worker-20241221/</id>
    <published>2024-12-21T08:00:50.000Z</published>
    <updated>2024-12-21T08:11:18.576Z</updated>
    
    
    <summary type="html">&lt;p&gt;基于shell的简单好用多进程wrapper...&lt;/p&gt;</summary>
    
    
    
    <category term="linux使用" scheme="https://fesianxu.github.io/categories/linux%E4%BD%BF%E7%94%A8/"/>
    
    
    <category term="linux 日常使用技巧" scheme="https://fesianxu.github.io/tags/linux-%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    
    <category term="工作实践经验" scheme="https://fesianxu.github.io/tags/%E5%B7%A5%E4%BD%9C%E5%AE%9E%E8%B7%B5%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>CatLIP，加速2.7倍！采用分类损失的CLIP水准的预训练视觉编码器</title>
    <link href="https://fesianxu.github.io/2024/11/10/catlip-20241110/"/>
    <id>https://fesianxu.github.io/2024/11/10/catlip-20241110/</id>
    <published>2024-11-10T11:19:47.000Z</published>
    <updated>2024-11-10T12:36:30.927Z</updated>
    
    
    <summary type="html">&lt;p&gt;传统的CLIP采用对比学习的方式进行预训练，通常需要汇聚多张节点的多张设备的特征向量以进行打分矩阵的计算，训练速度通常都较慢...&lt;/p&gt;</summary>
    
    
    
    <category term="多模态模型" scheme="https://fesianxu.github.io/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="对比学习" scheme="https://fesianxu.github.io/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="视觉底座模型" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E5%BA%95%E5%BA%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="图文预训练" scheme="https://fesianxu.github.io/tags/%E5%9B%BE%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>利用远程服务器实现内网穿透访问jupyter notebook</title>
    <link href="https://fesianxu.github.io/2024/11/06/remote-server-for-jupyter-notebook-20241106/"/>
    <id>https://fesianxu.github.io/2024/11/06/remote-server-for-jupyter-notebook-20241106/</id>
    <published>2024-11-05T16:35:15.000Z</published>
    <updated>2024-11-10T11:40:53.181Z</updated>
    
    
    <summary type="html">&lt;p&gt;穿透内网，访问jupyter notebook...&lt;/p&gt;</summary>
    
    
    
    <category term="深度学习环境搭建" scheme="https://fesianxu.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
    
    <category term="工作环境搭建" scheme="https://fesianxu.github.io/tags/%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>pytorch手动实现滑动窗口操作，论fold和unfold函数的使用</title>
    <link href="https://fesianxu.github.io/2024/11/06/pytorch-fold-unfold-20241106/"/>
    <id>https://fesianxu.github.io/2024/11/06/pytorch-fold-unfold-20241106/</id>
    <published>2024-11-05T16:31:38.000Z</published>
    <updated>2024-11-10T10:51:17.698Z</updated>
    
    
    <summary type="html">&lt;p&gt;pytorch中&lt;code&gt;fold&lt;/code&gt;和&lt;code&gt;unfold&lt;/code&gt;函数的日常使用方法...&lt;/p&gt;</summary>
    
    
    
    <category term="pytorch使用" scheme="https://fesianxu.github.io/categories/pytorch%E4%BD%BF%E7%94%A8/"/>
    
    
    <category term="pytorch使用教程" scheme="https://fesianxu.github.io/tags/pytorch%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>rsync 用于远程/本地 文件的拷贝（可以实现差量复制）</title>
    <link href="https://fesianxu.github.io/2024/11/06/rsync-cmd-20241106/"/>
    <id>https://fesianxu.github.io/2024/11/06/rsync-cmd-20241106/</id>
    <published>2024-11-05T16:29:17.000Z</published>
    <updated>2024-12-21T08:14:28.688Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;rsync&lt;/code&gt;的基本使用方法...&lt;/p&gt;</summary>
    
    
    
    <category term="linux使用" scheme="https://fesianxu.github.io/categories/linux%E4%BD%BF%E7%94%A8/"/>
    
    
    <category term="linux常见命令" scheme="https://fesianxu.github.io/tags/linux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>解耦多模态大模型中的视觉语义压缩与视觉语义摘要</title>
    <link href="https://fesianxu.github.io/2024/11/06/decouple-compression-abstraction-mllm-20241106/"/>
    <id>https://fesianxu.github.io/2024/11/06/decouple-compression-abstraction-mllm-20241106/</id>
    <published>2024-11-05T16:22:11.000Z</published>
    <updated>2024-11-05T16:26:24.697Z</updated>
    
    
    <summary type="html">&lt;p&gt;在多模态大模型中，视觉连接器大致可以分为压缩型和非圧缩型，其中BLIP2提出的Q-Former
[1] 是压缩型视觉连接器的代表工作之一。在论文 [2]
中，作者对Q-Former的作用提出了质疑和分析，本文进行笔记，希望对读者有所帮助...&lt;/p&gt;</summary>
    
    
    
    <category term="多模态大模型" scheme="https://fesianxu.github.io/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="多模态大模型" scheme="https://fesianxu.github.io/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="视觉连接器" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E8%BF%9E%E6%8E%A5%E5%99%A8/"/>
    
    <category term="视觉语义压缩" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E8%AF%AD%E4%B9%89%E5%8E%8B%E7%BC%A9/"/>
    
    <category term="视觉语义摘要" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E8%AF%AD%E4%B9%89%E6%91%98%E8%A6%81/"/>
    
    <category term="多模态信息提取" scheme="https://fesianxu.github.io/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"/>
    
  </entry>
  
  <entry>
    <title>Flamingo：一种交织图文的视觉语言大模型方法</title>
    <link href="https://fesianxu.github.io/2024/10/18/flamingo-20241018/"/>
    <id>https://fesianxu.github.io/2024/10/18/flamingo-20241018/</id>
    <published>2024-10-17T16:19:36.000Z</published>
    <updated>2024-10-17T16:28:00.746Z</updated>
    
    
    <summary type="html">&lt;p&gt;Flamingo算是DeepMind的多模态融合LLM的一个较老的工作了（2022年），之前粗略读过没来得及及时总结，本次过年笔者重新细读了论文，发现其在50多页的论文中有着不少细节...&lt;/p&gt;</summary>
    
    
    
    <category term="多模态大模型" scheme="https://fesianxu.github.io/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="多模态大模型" scheme="https://fesianxu.github.io/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="视觉连接器" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E8%BF%9E%E6%8E%A5%E5%99%A8/"/>
    
    <category term="交织图文训练" scheme="https://fesianxu.github.io/tags/%E4%BA%A4%E7%BB%87%E5%9B%BE%E6%96%87%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>搜索系统中的Learning To Rank模型：GBRank</title>
    <link href="https://fesianxu.github.io/2024/10/18/gbrank-20241018/"/>
    <id>https://fesianxu.github.io/2024/10/18/gbrank-20241018/</id>
    <published>2024-10-17T16:06:59.000Z</published>
    <updated>2024-10-17T16:17:18.424Z</updated>
    
    
    <summary type="html">&lt;p&gt;Learning To
Rank(LTR)模型是对搜索/计算广告/推荐系统中的排序问题进行模型建模的方法，在当前的搜索系统中有着至关重要的作用...&lt;/p&gt;</summary>
    
    
    
    <category term="统计机器学习" scheme="https://fesianxu.github.io/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="搜索系统" scheme="https://fesianxu.github.io/tags/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="gbrank" scheme="https://fesianxu.github.io/tags/gbrank/"/>
    
    <category term="LTR" scheme="https://fesianxu.github.io/tags/LTR/"/>
    
  </entry>
  
  <entry>
    <title>【用户行为学研究】 从用户点击数据中构造隐式反馈</title>
    <link href="https://fesianxu.github.io/2024/10/17/above-skip-20241017/"/>
    <id>https://fesianxu.github.io/2024/10/17/above-skip-20241017/</id>
    <published>2024-10-17T15:54:19.000Z</published>
    <updated>2024-10-17T16:18:42.477Z</updated>
    
    
    <summary type="html">&lt;p&gt;笔者在前文[4]中介绍了LTR模型中常用的GBRank模型，在文章末尾提到了根据用户点击数据构造隐式反馈，从而构建出有序对数据进行训练，因而引出了&lt;code&gt;Skip-Above&lt;/code&gt;这个构建隐式反馈的方法，该方法在文章[1]中提出，作者根据翔实的用户行为学实验和分析，得出了包括&lt;code&gt;Skip-Above&lt;/code&gt;在内的一系列通过点击信号来构建隐式反馈的方法...&lt;/p&gt;</summary>
    
    
    
    <category term="用户行为学" scheme="https://fesianxu.github.io/categories/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%AD%A6/"/>
    
    
    <category term="用户行为学" scheme="https://fesianxu.github.io/tags/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%AD%A6/"/>
    
    <category term="隐式反馈" scheme="https://fesianxu.github.io/tags/%E9%9A%90%E5%BC%8F%E5%8F%8D%E9%A6%88/"/>
    
    <category term="用户行为分析" scheme="https://fesianxu.github.io/tags/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Alignment与Correspondence，用于量化衡量MLLM中视觉特征的视觉语义对齐与视觉结构程度的方法</title>
    <link href="https://fesianxu.github.io/2024/10/15/ac-score-for-mllm-20241015/"/>
    <id>https://fesianxu.github.io/2024/10/15/ac-score-for-mllm-20241015/</id>
    <published>2024-10-15T15:26:10.000Z</published>
    <updated>2024-10-15T15:36:42.636Z</updated>
    
    
    <summary type="html">&lt;p&gt;在多模态大模型（Multimodal Large Language Model，
MLLM）中，视觉特征就像是人的眼睛，而底座的LLM则像是人的大脑，合适的视觉特征的选择通常都是一个MLLM成功的重要一步...&lt;/p&gt;</summary>
    
    
    
    <category term="多模态大模型" scheme="https://fesianxu.github.io/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
    <category term="多模态大模型" scheme="https://fesianxu.github.io/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="视觉语义对齐" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E8%AF%AD%E4%B9%89%E5%AF%B9%E9%BD%90/"/>
    
    <category term="视觉结构特征" scheme="https://fesianxu.github.io/tags/%E8%A7%86%E8%A7%89%E7%BB%93%E6%9E%84%E7%89%B9%E5%BE%81/"/>
    
  </entry>
  
</feed>
