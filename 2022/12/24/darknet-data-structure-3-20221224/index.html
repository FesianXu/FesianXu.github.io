<!doctypehtml><html class="theme-next muse use-motion" lang=zh-CN><meta charset=UTF-8><meta content=IE=edge http-equiv=X-UA-Compatible><meta content=width=device-width,initial-scale=1,maximum-scale=1 name=viewport><meta content=#222 name=theme-color><meta content=no-transform http-equiv=Cache-Control><meta content=no-siteapp http-equiv=Cache-Control><link href=/lib/fancybox/source/jquery.fancybox.css?v=2.1.5 rel=stylesheet><link href=/lib/font-awesome/css/font-awesome.min.css?v=4.6.2 rel=stylesheet><link href=/css/main.css?v=5.1.4 rel=stylesheet><link href=/images/apple-touch-icon-next.png?v=5.1.4 rel=apple-touch-icon sizes=180x180><link href=/images/favicon-32x32-next.png?v=5.1.4 rel=icon sizes=32x32 type=image/png><link href=/images/favicon-16x16-next.png?v=5.1.4 rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg?v=5.1.4 rel=mask-icon><meta content=darknet源码,深度学习系统, name=keywords><meta content=最近笔者在好奇如何从最底层开始搭建一个深度学习系统，之前都是采用现成的成熟深度学习框架，比如PyTorch，TensorFlow等进行模型的搭建，对底层原理了解不是特别深刻。因此笔者最近在阅读darknet的源码，希望能从中学习到一些底层的知识，本文主要是对darknet中常见的数据结构进行记录和分析。 name=description><meta content=article property=og:type><meta content="【darknet源码系列-1】 darknet源码中的常见数据结构" property=og:title><meta content=https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/index.html property=og:url><meta content=机器学习杂货铺总店 property=og:site_name><meta content=最近笔者在好奇如何从最底层开始搭建一个深度学习系统，之前都是采用现成的成熟深度学习框架，比如PyTorch，TensorFlow等进行模型的搭建，对底层原理了解不是特别深刻。因此笔者最近在阅读darknet的源码，希望能从中学习到一些底层的知识，本文主要是对darknet中常见的数据结构进行记录和分析。 property=og:description><meta content=zh_CN property=og:locale><meta content=https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/qrcode.png property=og:image><meta content=https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/imgs/double_linked_list.png property=og:image><meta content=https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/imgs/section_linked_list.png property=og:image><meta content=2022-12-24T03:52:00.000Z property=article:published_time><meta content=2022-12-24T15:36:18.372Z property=article:modified_time><meta content=FesianXu property=article:author><meta content=darknet源码 property=article:tag><meta content=深度学习系统 property=article:tag><meta content=summary name=twitter:card><meta content=https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/qrcode.png name=twitter:image><script id=hexo.configurations>var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };</script><link href=https://FesianXu.github.io/2022/12/24/darknet-data-structure-3-20221224/ rel=canonical><title>【darknet源码系列-1】 darknet源码中的常见数据结构 | 机器学习杂货铺总店</title><meta content="Hexo 5.4.2" name=generator><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}</style><body itemscope itemtype=http://schema.org/WebPage lang=zh-CN><div class="container sidebar-position-left page-post-detail"><div class=headband></div><header class=header id=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-wrapper><div class=site-meta><div class=custom-logo-site-title><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <span class=site-title>机器学习杂货铺总店</span> <span class=logo-line-after><i></i></span> </a></div><p class=site-subtitle></div><div class=site-nav-toggle><button><span class=btn-bar></span> <span class=btn-bar></span> <span class=btn-bar></span></button></div></div><nav class=site-nav><ul class=menu id=menu><li class="menu-item menu-item-home"><a href=/ rel=section> <i class="menu-item-icon fa fa-fw fa-home"></i> <br> Home </a><li class="menu-item menu-item-about"><a href=/about/ rel=section> <i class="menu-item-icon fa fa-fw fa-user"></i> <br> About </a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section> <i class="menu-item-icon fa fa-fw fa-tags"></i> <br> Tags </a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section> <i class="menu-item-icon fa fa-fw fa-th"></i> <br> Categories </a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section> <i class="menu-item-icon fa fa-fw fa-archive"></i> <br> Archives </a><li class="menu-item menu-item-search"><a class=popup-trigger href=javascript:;> <i class="menu-item-icon fa fa-search fa-fw"></i> <br> Search </a></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon> <i class="fa fa-search"></i> </span><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span><div class=local-search-input-wrapper><input autocomplete=off id=local-search-input placeholder=Searching... spellcheck=false></div></div><div id=local-search-result></div></div></div></nav></div></header><main class=main id=main><div class=main-inner><div class=content-wrap><div class=content id=content><div class=posts-expand id=posts><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><div class=post-block><link href=https://FesianXu.github.io/2022/12/24/darknet-data-structure-3-20221224/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta itemprop=name> <meta itemprop=description> <meta content=/%5Bobject%20Object%5D itemprop=image> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=机器学习杂货铺总店 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>【darknet源码系列-1】 darknet源码中的常见数据结构</h1><div class=post-meta><span class=post-time> <span class=post-meta-item-icon> <i class="fa fa-calendar-o"></i> </span> <span class=post-meta-item-text>Posted on</span> <time itemprop="dateCreated datePublished" title="Post created" datetime=2022-12-24T11:52:00+08:00> 2022-12-24 </time> </span><span class=post-category> <span class=post-meta-divider>|</span> <span class=post-meta-item-icon> <i class="fa fa-folder-o"></i> </span> <span class=post-meta-item-text>In</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/ itemprop=url rel=index> <span itemprop=name>深度学习系统</span> </a> </span> </span><span class=post-meta-divider>|</span><span class=page-pv><i class="fa fa-file-o"></i> <span class=busuanzi-value id=busuanzi_value_page_pv></span> </span><div class=post-wordcount><span class=post-meta-item-icon> <i class="fa fa-file-word-o"></i> </span><span class=post-meta-item-text>Words count in article:</span><span title="Words count in article"> 4k 字 </span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-clock-o"></i> </span><span class=post-meta-item-text>Reading time ≈</span><span title="Reading time"> 15 分钟 </span></div></div></header><div class=post-body itemprop=articleBody><p>最近笔者在好奇如何从最底层开始搭建一个深度学习系统，之前都是采用现成的成熟深度学习框架，比如<code>PyTorch</code>，<code>TensorFlow</code>等进行模型的搭建，对底层原理了解不是特别深刻。因此笔者最近在阅读darknet的源码，希望能从中学习到一些底层的知识，本文主要是对darknet中常见的数据结构进行记录和分析。 <span id=more></span><div align=right>FesianXu 20201117 at UESTC</div><h1 id=前言>前言</h1><p>最近笔者在好奇如何从最底层开始搭建一个深度学习系统，之前都是采用现成的成熟深度学习框架，比如<code>PyTorch</code>，<code>TensorFlow</code>等进行模型的搭建，对底层原理了解不是特别深刻。因此笔者最近在阅读darknet的源码，希望能从中学习到一些底层的知识，本文主要是对darknet中常见的数据结构进行记录和分析。<strong>如有谬误请联系指出，转载请联系作者并注明出处，谢谢</strong>。<p><span class="math inline"><mjx-container class=MathJax jax=SVG><svg style="vertical-align: -0.075ex;" viewbox="0 -683 833 716" focusable=false height=1.62ex role=img width=1.885ex xmlns=http://www.w3.org/2000/svg><g fill=currentColor stroke=currentColor stroke-width=0 transform=scale(1,-1)><g data-mml-node=math><g data-mml-node=mi><path d="M46 676Q46 679 51 683H781Q786 679 786 676Q786 674 617 326T444 -26Q439 -33 416 -33T388 -26Q385 -22 216 326T46 676ZM697 596Q697 597 445 597T193 596Q195 591 319 336T445 80L697 596Z" data-c=2207 /></g></g></g></svg></mjx-container></span> 联系方式：<p><strong>e-mail</strong>: FesianXu@gmail.com<p><strong>QQ</strong>: 973926198<p><strong>github</strong>: https://github.com/FesianXu<p><strong>知乎专栏</strong>: <a href=https://zhuanlan.zhihu.com/c_1265262560611299328 rel=noopener target=_blank>计算机视觉/计算机图形理论与应用</a><p><strong>微信公众号</strong>： <img alt=qrcode src=/2022/12/24/darknet-data-structure-3-20221224/qrcode.png><hr><h1 id=darknet>DarkNet</h1><p><code>darknet</code> [1]是一个纯由C语言编码而成的轻量级深度学习框架，在最小运行状态下（即是不使用GPU，不使用多线程和opencv）时，可以实现无外部库依赖实现深度学习建模，训练，测试等基础功能。如果从<code>caffe</code>,<code>pytorch</code>,<code>tensorflow</code>等大型深度学习库开始去研究底层，因为代码结构复杂，而且依赖项太多，使得入门者望而却步，由于<code>darknet</code>可以在无依赖的情况下运行，因此是研究深度学习框架底层代码的一个很好的资源。<p><code>darknet</code>中定义了很多必要的数据结构去表示网络结构，网络层结构等，这些数据结构为网络配置解析提供了方便，是阅读源码过程中必不可少的，本文主要分析<code>darknet</code>中主要的数据结构。<h1 id=数据结构>数据结构</h1><h2 id=为了解析方便而定义的数据结构>为了解析方便而定义的数据结构</h2><p>类似于在<code>caffe</code>中利用<code>prototxt</code>文件去表示一个网络的结构，每一层的超参数以及整个网络的超参数（例如学习率，优化器参数等），在<code>darknet</code>中采用了<code>cfg</code>文件去配置网络的这一切参数，可以视为是简单版本的<code>prototxt</code>文件，以下以<code>resnet18.cfg</code>为例子，截取了其中的头尾部分的<code>cfg</code>片段：<figure class="highlight shell"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br></pre><td class=code><pre><span class=line>[net]</span><br><span class=line><span class="meta prompt_"># </span><span class=language-bash>Training</span></span><br><span class=line><span class="meta prompt_"># </span><span class=language-bash>batch=128</span></span><br><span class=line><span class="meta prompt_"># </span><span class=language-bash>subdivisions=1</span></span><br><span class=line><span class="meta prompt_"></span></span><br><span class=line><span class="meta prompt_"># </span><span class=language-bash>Testing</span></span><br><span class=line>batch=1</span><br><span class=line>subdivisions=1</span><br><span class=line></span><br><span class=line>height=256</span><br><span class=line>width=256</span><br><span class=line>channels=3</span><br><span class=line>min_crop=128</span><br><span class=line>max_crop=448</span><br><span class=line></span><br><span class=line>burn_in=1000</span><br><span class=line>learning_rate=0.1</span><br><span class=line>policy=poly</span><br><span class=line>power=4</span><br><span class=line>max_batches=800000</span><br><span class=line>momentum=0.9</span><br><span class=line>decay=0.0005</span><br><span class=line></span><br><span class=line>...</span><br><span class=line></span><br><span class=line>[convolutional]</span><br><span class=line>batch_normalize=1</span><br><span class=line>filters=64</span><br><span class=line>size=7</span><br><span class=line>stride=2</span><br><span class=line>pad=1</span><br><span class=line>activation=leaky</span><br><span class=line></span><br><span class=line>[maxpool]</span><br><span class=line>size=2</span><br><span class=line>stride=2</span><br><span class=line></span><br><span class=line>...</span><br><span class=line></span><br><span class=line>[convolutional]</span><br><span class=line>filters=1000</span><br><span class=line>size=1</span><br><span class=line>stride=1</span><br><span class=line>pad=1</span><br><span class=line>activation=linear</span><br><span class=line></span><br><span class=line>[softmax]</span><br><span class=line>groups=1</span><br></pre></table></figure><div align=center><b> code 1. resnet18.cfg的节选片段示例。 </b></div><p>其中每一个<code>[xxx]</code>代表一个<strong>片区(section)</strong>，通常表示的是一个 <strong>层（layer）</strong>。其中的第一个片区<code>[net]</code>或者<code>[network]</code>是表示该网络的基本参数，比如图片长度，高度通道数，<code>batch_size</code>，学习率，优化器参数等。每个配置文件必须以<code>[net]</code>起始。<p>为了解析该文本配置文件的方便，我们需要用一种数据结构将整个网络配置串联起来，最理想的莫过于是 <strong>链表(linked list)</strong> 了，其中链表中的每个元素都是一个片区，该链表的数据结构定义如下，为了更好地组织数据，定义的是双向链表，因此每个节点<code>node</code>都有前项<code>prev</code>和后继<code>next</code>节点指针，当然还有内容负载指针 <code>void* val</code>。<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span> <span class=title>node</span>{</span></span><br><span class=line>    <span class=type>void</span> *val; <span class=comment>// 节点内容负载</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>node</span> *<span class=title>next</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>node</span> *<span class=title>prev</span>;</span></span><br><span class=line>} node;</span><br><span class=line></span><br><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span> <span class=title>list</span>{</span></span><br><span class=line>    <span class=type>int</span> size;</span><br><span class=line>    node *front; <span class=comment>// 双向链表头结点</span></span><br><span class=line>    node *back;  <span class=comment>// 双向链表尾节点</span></span><br><span class=line>} <span class=built_in>list</span>;</span><br></pre></table></figure><div align=center><b> code 2. 关于双向链表和节点的定义。 </b></div><p>因此可视化出来Fig 1所示，其中的负载既可以是<code>section</code>，也可以是其他元素，比如<code>key-val</code>（键值）对，此处暂时以<code>section</code>为例子。<p><img src=/2022/12/24/darknet-data-structure-3-20221224/imgs/double_linked_list.png><div align=center><b> Fig 1. 以内容负载为section作为例子的双向链表，其中头尾元素需要特别用指针标记出。 </b></div><p>其中每个<code>section</code>都是神经网络的一个层（除了第一个<code>section</code>，第一个是特殊的<code>[net]</code>参数组），<code>section</code>的数据结构定义如code 3所示，其中的<code>char* type</code>表示该层的名字，比如<code>[convolutional]</code>，<code>[avgpool]</code>等；其中的<code>list* options</code>表示的是该层中的每一个参数的 <strong>键值对（key-val pair, kvp）</strong>,每一个键值对都是该层的一个具体参数，比如<code>[convolutional]</code>的<code>stride=1</code>就表示其步进长度，我们需要用一个键值对数据结构进行表示，如code 4所示。<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span>{</span></span><br><span class=line>    <span class=type>char</span> *type;</span><br><span class=line>    <span class=built_in>list</span> *options;</span><br><span class=line>}section;</span><br></pre></table></figure><div align=center><b> code 3. 片段section数据结构的定义。 </b></div><figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span>{</span></span><br><span class=line>    <span class=type>char</span> *key; <span class=comment>// 索引键</span></span><br><span class=line>    <span class=type>char</span> *val; <span class=comment>// 对应值</span></span><br><span class=line>    <span class=type>int</span> used;  <span class=comment>// 是否被使用</span></span><br><span class=line>} kvp;</span><br></pre></table></figure><div align=center><b> code 4. 键值对kvp数据结构的定义。 </b></div><p>如Fig 2所示，当考虑到每个<code>section</code>内的参数kvp之后，我们有新的"链表套链表"的结构，采用该结构就足以表达整个网络的层次与参数了。<p><img src=/2022/12/24/darknet-data-structure-3-20221224/imgs/section_linked_list.png><div align=center><b> Fig 2. 当把section内部的kvp考虑了之后，结合Fig 1形成了最终的网络结构化表达形式。 </b></div><h2 id=网络结构的数据结构>网络结构的数据结构</h2><p>之前谈到的数据结构是为了解析<code>cfg</code>文件方便而定义的，考虑到网络的计算（包括前向和后向计算），参数保存等，我们还需要一些其他数据结构，这些数据结构可以基于解析得到的双向网络配置链表，初始化整个神经网络的参数和结构。这些数据结构中，最重要的莫过于<code>layer</code>和<code>network</code>，这两个结构体都在<code>/include/darknet.h</code>中定义。<p><code>layer</code>的数据结构定义如code 5所示（省略掉了很多元素以便于展示，具体定义见[2]），我们发现这个定义中有着非常多的元素（其实我还省略掉了一些和GPU计算有关的元素，因为在本文中假设只使用CPU进行计算，这样又便于我们分析整体代码的结构。），其中元素那么多的原因在于，作者采用的纯C语言的编写方式，没办法直接采用C++的面向对象的思想设计代码，这意味着不能通过继承的方式，设置一个<code>layer</code>父类，然后不同的<code>convolution_layer</code>,<code>rnn_layer</code>,<code>crnn_layer</code>,<code>cost_layer</code>,<code>connected_layer</code>等子类继承这个共有的父类，因为不同子类（也就是不同层）的参数类别千差万别，因此可以做到比较好的隔离。然而，C语言是面向过程编程的，因此作者设计的<code>layer</code>类就必须包括该框架中需要的所有层的所有参数类别，这使得该数据结构异常的臃肿，而且难以扩展，定制其他层。不过暂且不讨论这些缺点，我们先看看该层中有哪些参数需要注意的吧。<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br></pre><td class=code><pre><span class=line><span class=class><span class=keyword>struct</span> <span class=title>layer</span>{</span></span><br><span class=line>    LAYER_TYPE type;</span><br><span class=line>    ACTIVATION activation;</span><br><span class=line>    COST_TYPE cost_type;</span><br><span class=line>    <span class=type>void</span> (*forward)   (<span class=keyword>struct</span> layer, <span class=keyword>struct</span> network);</span><br><span class=line>    <span class=type>void</span> (*backward)  (<span class=keyword>struct</span> layer, <span class=keyword>struct</span> network);</span><br><span class=line>    <span class=type>void</span> (*update)    (<span class=keyword>struct</span> layer, update_args);</span><br><span class=line>    <span class=type>int</span> batch_normalize;</span><br><span class=line>    <span class=type>int</span> shortcut;</span><br><span class=line>    <span class=type>int</span> batch;</span><br><span class=line>    <span class=type>int</span> forced;</span><br><span class=line>    <span class=type>int</span> flipped;</span><br><span class=line>    <span class=type>int</span> inputs;</span><br><span class=line>    <span class=type>int</span> outputs;</span><br><span class=line>    <span class=type>int</span> nweights;</span><br><span class=line>    <span class=type>int</span> nbiases;</span><br><span class=line>    <span class=type>int</span> extra;</span><br><span class=line>...</span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>wo</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>uf</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>wf</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>ui</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>wi</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>ug</span>;</span></span><br><span class=line>    <span class=class><span class=keyword>struct</span> <span class=title>layer</span> *<span class=title>wg</span>;</span></span><br><span class=line>    tree *softmax_tree;</span><br><span class=line>    <span class=type>size_t</span> workspace_size;</span><br><span class=line>};</span><br></pre></table></figure><div align=center><b> code 5. layer的定义，其中为了简便，省略掉了和GPU计算有关的元素，和大部分中间的元素，只展示了头尾的部分元素。 </b></div><p>第一个元素<code>LAYER_TYPE</code>是一个枚举类型，用于指定该层的类型；第二个元素<code>ACTIVATION</code>也是一个枚举类型，指定激活函数类型；第三个元素<code>COST_TYPE</code>同样是枚举类型，指定损失函数类型。5-7行的三个函数指针（函数指针是指向函数的指针变量，即本质是一个指针变量）比较特别，是指的该层的前向传播计算细节<code>void (*forward)(struct layer, struct network);</code>，该层的反向传播计算细节<code>void (*backward)(struct layer, struct network);</code>，以及模型训练过程中的参数更新策略<code>void (*update)(struct layer, update_args);</code>。这些函数指针都需要根据特定的具体层进行特别指定，因此是一种回调函数，需要指定层进行特定的回调函数注册。大部分神经网络层都会有其特有的参数，比如卷积层的其中一些参数示例，其中以指针形式出现的参数都是需要学习的（也需要初始化），以其他参数大多数都是超参数：<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line><span class=type>float</span> * weights; <span class=comment>// 卷积权值</span></span><br><span class=line><span class=type>float</span> * biases; <span class=comment>// 偏置</span></span><br><span class=line><span class=type>int</span> nweights; <span class=comment>// 权值参数量</span></span><br><span class=line><span class=type>int</span> nbiases; <span class=comment>// 偏置参数量</span></span><br><span class=line><span class=type>int</span> groups; <span class=comment>// 组可分离卷积的组数</span></span><br><span class=line><span class=type>int</span> stride; <span class=comment>// 步进</span></span><br><span class=line><span class=type>int</span> pad;    <span class=comment>// 填充大小</span></span><br><span class=line>...</span><br></pre></table></figure><p>还有些参数是每个层都共用的，比如输入指针，输出指针等：<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line><span class=type>int</span>   * input_layers; <span class=comment>// 该层的上一层，也即是输入层</span></span><br><span class=line><span class=type>int</span>   * input_sizes;</span><br><span class=line><span class=type>float</span> * output; <span class=comment>// 该层的输出</span></span><br><span class=line>...</span><br></pre></table></figure><p>当然，<code>layer</code>数据结构还有很多其他元素，比如<code>batch_normalize</code>是否运行<code>batch_norm</code>[3]，是否该层存在<code>shortcut</code>等，注意到因为<code>darknet</code>是为了<code>yolo</code>系列网络[4,5,6]专门设计的框架，因此<code>layer</code>中还有很多元素是和<code>yolo</code>网络有关的，这点不再进一步阐述，我们只关注通用的神经网络底层需要的元素。<p>这个只是一个神经网络层的数据结构定义而已，为了表示整个神经网络结构，还需要定义一个<code>network</code>数据结构，如code 6所示，该数据结构储存有定义整个网络必须的元素，比如<code>batch size</code>大小，<code>epoch</code>大小，每一层的定义<code>layer* layers</code>，学习率更新策略，学习率，动量等等。我们需要做的就是利用解析好的网络配置链表，基于<code>network</code>数据结构去初始化该数据结构，通过这个数据结构就可以表示整个网络，而且具备有计算，梯度传导，参数更新等功能，可以视为是一个完整的单元了。<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br><span class=line>44</span><br><span class=line>45</span><br><span class=line>46</span><br><span class=line>47</span><br><span class=line>48</span><br><span class=line>49</span><br><span class=line>50</span><br><span class=line>51</span><br><span class=line>52</span><br><span class=line>53</span><br><span class=line>54</span><br><span class=line>55</span><br><span class=line>56</span><br><span class=line>57</span><br><span class=line>58</span><br><span class=line>59</span><br><span class=line>60</span><br><span class=line>61</span><br><span class=line>62</span><br><span class=line>63</span><br><span class=line>64</span><br><span class=line>65</span><br><span class=line>66</span><br><span class=line>67</span><br><span class=line>68</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span> <span class=title>network</span>{</span></span><br><span class=line>    <span class=type>int</span> n; <span class=comment>// 网络中层的数量</span></span><br><span class=line>    <span class=type>int</span> batch; <span class=comment>// 批次大小</span></span><br><span class=line>    <span class=type>size_t</span> *seen; <span class=comment>// 已经有多少图片被处理过了</span></span><br><span class=line>    <span class=type>int</span> *t; <span class=comment>// ?</span></span><br><span class=line>    <span class=type>float</span> epoch; <span class=comment>// 世代大小</span></span><br><span class=line>    <span class=type>int</span> subdivisions; <span class=comment>// 子划分</span></span><br><span class=line>    layer *layers; <span class=comment>// 每一个层的定义</span></span><br><span class=line>    <span class=type>float</span> *output; <span class=comment>// 输出</span></span><br><span class=line>    learning_rate_policy policy; <span class=comment>// 学习率更新策略</span></span><br><span class=line></span><br><span class=line>    <span class=type>float</span> learning_rate; <span class=comment>// 学习率</span></span><br><span class=line>    <span class=type>float</span> momentum;   <span class=comment>// SGD动量大小</span></span><br><span class=line>    <span class=type>float</span> decay;     <span class=comment>// L2正则衰减系数</span></span><br><span class=line>    <span class=type>float</span> gamma; </span><br><span class=line>    <span class=type>float</span> scale;</span><br><span class=line>    <span class=type>float</span> power;</span><br><span class=line>    <span class=type>int</span> time_steps;</span><br><span class=line>    <span class=type>int</span> step;</span><br><span class=line>    <span class=type>int</span> max_batches;</span><br><span class=line>    <span class=type>float</span> *scales;</span><br><span class=line>    <span class=type>int</span>   *steps;</span><br><span class=line>    <span class=type>int</span> num_steps;</span><br><span class=line>    <span class=type>int</span> burn_in;</span><br><span class=line>	<span class=comment>// 和adam优化器相关的参数</span></span><br><span class=line>    <span class=type>int</span> adam;</span><br><span class=line>    <span class=type>float</span> B1;</span><br><span class=line>    <span class=type>float</span> B2;</span><br><span class=line>    <span class=type>float</span> eps;</span><br><span class=line>	<span class=comment>// 输入输出的维度</span></span><br><span class=line>    <span class=type>int</span> inputs;</span><br><span class=line>    <span class=type>int</span> outputs;</span><br><span class=line>    <span class=comment>// ground truth的维度</span></span><br><span class=line>    <span class=type>int</span> truths;</span><br><span class=line>    <span class=type>int</span> notruth;</span><br><span class=line>    <span class=type>int</span> h, w, c;</span><br><span class=line>    <span class=type>int</span> max_crop;</span><br><span class=line>    <span class=type>int</span> min_crop;</span><br><span class=line>    <span class=type>float</span> max_ratio;</span><br><span class=line>    <span class=type>float</span> min_ratio;</span><br><span class=line>    <span class=type>int</span> center;</span><br><span class=line>    <span class=type>float</span> angle;</span><br><span class=line>    <span class=type>float</span> aspect;</span><br><span class=line>    <span class=type>float</span> exposure;</span><br><span class=line>    <span class=type>float</span> saturation;</span><br><span class=line>    <span class=type>float</span> hue;</span><br><span class=line>    <span class=type>int</span> random;</span><br><span class=line>    <span class=comment>// darknet对于每个GPU都维护着同一个网络network，每个network通过gpu_index进行区分</span></span><br><span class=line>    <span class=type>int</span> gpu_index;</span><br><span class=line>    tree *hierarchy;</span><br><span class=line>	</span><br><span class=line>    <span class=comment>// 中间变量，用于临时存储某一层的输入，包括一个批次的输入，用于完成前向和反向传播。</span></span><br><span class=line>    <span class=type>float</span> *input;</span><br><span class=line>    <span class=comment>// 中间变量，和上面的输入是对应的，用于临时储存对应的标签数据。</span></span><br><span class=line>    <span class=type>float</span> *truth; </span><br><span class=line>    <span class=comment>// delta用于梯度传播，也是一个临时变量，用于临时储存某个层的sensitivity map。在反向传播的时候，当经过当前层的时候，需要储存之前层的sensitivity map。我们会后续讨论。</span></span><br><span class=line>    <span class=type>float</span> *delta;</span><br><span class=line>    <span class=comment>// workspace 是公共的运行空间，用于纪录所有层中需要的最大计算内容空间，其大小为workspace_size。因为在GPU或者CPU中，同一时间只有一个层在运行，因此保存所有层中最大的需求即可。net.workspace用于储存feature特征。</span></span><br><span class=line>    <span class=type>float</span> *workspace;</span><br><span class=line>    <span class=comment>// 这个标识参数用于判断网络是否处于训练状态，如果是，这个值为1。在一些操作中，比如dropout层，forward_dropout_layer()只在训练阶段才会被采用。</span></span><br><span class=line>    <span class=type>int</span> train;</span><br><span class=line>    <span class=comment>// 标识参数，指明了当前网络的活跃（active）层</span></span><br><span class=line>    <span class=type>int</span> index;</span><br><span class=line>    <span class=comment>// 每一层的loss，只有[yolo]层才会有值。</span></span><br><span class=line>    <span class=type>float</span> *cost;</span><br><span class=line>    <span class=type>float</span> clip;</span><br><span class=line>} network;</span><br><span class=line></span><br></pre></table></figure><div align=center><b> code 6. network数据结构的定义。 </b></div><p>从code 6中，备注了大部分参数的含义，其中需要解释的是<code>subdivisions</code>，子划分[7]的作用是对<code>batch size</code>进行进一步的划分，以便于某些小显存的GPU也能够运行程序。例如本身设置的<code>batch size = 64</code>，如果GPU显存过小，不能负担大的<code>batch size</code>，那么通过设置<code>subdivisions = 8</code>，可以将一个批次分为8次完成（当然，梯度是会累积的，类似于[8]的操作），因此一个<code>mini batch size = 64/8 = 8</code>了，此时GPU显存就可以装得下了。<p>还有一个元素需要解释的就是<code>float *workspace</code>，该指针变量开辟了一大段<code>float</code>类型的内存空间，用于作为当前的运行环境。我们之后在讨论如何解析<code>darknet</code>的<code>cfg</code>配置文件的时候，会讨论如何确定这个<code>workspace</code>的空间大小。因为不管什么时候（不考虑多模型多设备并行），GPU或者CPU中只有模型的某一层在运行，因此只要求得所有层中的最大内存要求，然后根据这个内存要求开辟一个内存池用于作为模型的工作空间就足够了。因此不管是模型的哪个层，其特征feature都储存在了<code>workspace</code>。我们后续再继续讨论这个元素，目前知道它是一个公共内存空间即可。<h2 id=其他类型的数据结构>其他类型的数据结构</h2><p>以上提到的数据结构是为了解析网络配置，定义与初始化网络结构而设计的，有些数据结构则是为了作为喂入数据的容器而存在的，类似于<code>pytorch</code>中的<code>tensor</code>，不过<code>tensor</code>结构是自带梯度的，而<code>darknet</code>的只是为了喂数据而已，没有梯度信息，<code>darknet</code>的梯度流信息储存在了<code>network</code>中。<p>最基本的单元就是<code>matrix</code>，指定了行列数和一个二阶的单浮点指针表示数据负载，如code 7所示。<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span> <span class=title>matrix</span>{</span></span><br><span class=line>    <span class=type>int</span> rows, cols;</span><br><span class=line>    <span class=type>float</span> **vals;</span><br><span class=line>} matrix;</span><br></pre></table></figure><div align=center><b> code 7. matrix数据结构的定义。 </b></div><p>其中每一行是一个样本，每一列是一个特征维度，如果是图片样本，那需要把图片拉直成向量之后，塞到每一行。这个<code>matrix</code>既可以表示训练样本数据，也可以表示标签数据，因此有<code>data</code>数据结构。<figure class="highlight c"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br></pre><td class=code><pre><span class=line><span class=keyword>typedef</span> <span class=class><span class=keyword>struct</span>{</span></span><br><span class=line>    <span class=type>int</span> w, h;</span><br><span class=line>    matrix X;</span><br><span class=line>    matrix y;</span><br><span class=line>    <span class=type>int</span> shallow;</span><br><span class=line>    <span class=type>int</span> *num_boxes;</span><br><span class=line>    box **boxes;</span><br><span class=line>} data;</span><br></pre></table></figure><div align=center><b> code 8. data数据结构的定义。 </b></div><p>正如之前所述的，<code>darknet</code>为<code>yolo</code>量身定制，是进行目标识别任务的，因此<code>data</code>中会出现和目标检测有关的包围盒<code>box** boxes</code>等数据。<h1 id=总结>总结</h1><p>总得来说，<code>darknet</code>的常见数据类型主要有以下几种：<ol type=1><li><strong>解析配置文件时候的辅助数据结构</strong>：<code>node</code>, <code>list</code>, <code>kvp</code>,<code>section</code>。<li><strong>构建网络时候的数据结构</strong>： <code>layer</code>,<code>network</code>。<li><strong>数据管道的数据结构</strong>：<code>matrix</code>,<code>data</code>,<code>metadata</code>,<code>box_label</code>,<code>box</code>,<code>data_type</code>,<code>image</code>,<code>IMTYPE</code>,<code>detection</code>。<li><strong>网络相关，训练过程中的数据结构</strong>： <code>learning_rate_policy</code>,<code>ACTIVATION</code>,<code>BINARY_ACTIVATION</code>,<code>COST_TYPE</code>,<code>LAYER_TYPE</code>,<code>update_args</code>。<li><strong>暂时不知道拿来干啥用的数据结构</strong>： <code>tree</code>。</ol><h1 id=声明>声明</h1><p>该系列博客仍处在开发中，笔者还没完全通读完<code>darknet</code>，目前处在笔记阶段，可能会有所谬误，因此会随时存在更正更新，如有错误也欢迎各位读者朋友在评论区指出。<h1 id=reference>Reference</h1><p>[1]. https://pjreddie.com/darknet/<p>[2]. https://github.com/pjreddie/darknet/blob/4a03d405982aa1e1e911eac42b0ffce29cc8c8ef/include/darknet.h#L115<p>[3]. https://fesian.blog.csdn.net/article/details/86476010<p>[4]. Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You only look once: Unified, real-time object detection. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 779-788).<p>[5]. Redmon, J., & Farhadi, A. (2017). YOLO9000: better, faster, stronger. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 7263-7271).<p>[6]. Redmon, J., & Farhadi, A. (2018). Yolov3: An incremental improvement. <em>arXiv preprint arXiv:1804.02767</em>.<p>[7]. https://github.com/pjreddie/darknet/issues/224#issuecomment-335771840<p>[8]. https://blog.csdn.net/LoseInVain/article/details/82916163</div><div><ul class=post-copyright><li class=post-copyright-author><strong>Post author:</strong> FesianXu<li class=post-copyright-link><strong>Post link:</strong> <a title="【darknet源码系列-1】 darknet源码中的常见数据结构" href=https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/>https://fesianxu.github.io/2022/12/24/darknet-data-structure-3-20221224/</a><li class=post-copyright-license><strong>Copyright Notice: </strong> All articles in this blog are licensed under <a rel="external nofollow" href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank>CC BY-NC-SA 3.0</a> unless stating additionally.</ul></div><footer class=post-footer><div class=post-tags><a href=/tags/darknet%E6%BA%90%E7%A0%81/ rel=tag># darknet源码</a><a href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/ rel=tag># 深度学习系统</a></div><div class=post-nav><div class="post-nav-next post-nav-item"><a title="【darknet源码系列-3】 在darknet中，如何根据解析出来的配置进行网络层构建" href=/2022/12/24/darknet-network-build-2-20221224/ rel=next> <i class="fa fa-chevron-left"></i> 【darknet源码系列-3】 在darknet中，如何根据解析出来的配置进行网络层构建 </a></div><span class=post-nav-divider></span><div class="post-nav-prev post-nav-item"><a href=/2022/12/24/c-volatile-qualifier-20221224/ rel=prev title=一文理解C语言中的volatile修饰符> 一文理解C语言中的volatile修饰符 <i class="fa fa-chevron-right"></i> </a></div></div></footer></div></article><div class=post-spread></div></div></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside class=sidebar id=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>Table of Contents<li class=sidebar-nav-overview data-target=site-overview-wrap>Overview</ul><section class="site-overview-wrap sidebar-panel"><div class=site-overview><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt class=site-author-image itemprop=image src=/%5Bobject%20Object%5D><p class=site-author-name itemprop=name><p class="site-description motion-element" itemprop=description></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/archives/%7C%7C%20archive> <span class=site-state-item-count>50</span> <span class=site-state-item-name>posts</span> </a></div><div class="site-state-item site-state-categories"><span class=site-state-item-count>18</span><span class=site-state-item-name>categories</span></div><div class="site-state-item site-state-tags"><a href=/tags/index.html> <span class=site-state-item-count>104</span> <span class=site-state-item-name>tags</span> </a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item> <a href=https://github.com/FesianXu target=_blank title=GitHub> <i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class=links-of-author-item> <a href=mailto:FesianXu@gmail.com target=_blank title=E-Mail> <i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class=links-of-author-item> <a href=https://stackoverflow.com/users/7348519/fesianxu target=_blank title=StackOverflow> <i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a> </span></div></div></section><!--noindex--><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><ol class=nav><li class="nav-item nav-level-1"><a class=nav-link href=#%E5%89%8D%E8%A8%80><span class=nav-number>1.</span> <span class=nav-text>前言</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#darknet><span class=nav-number>2.</span> <span class=nav-text>DarkNet</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84><span class=nav-number>3.</span> <span class=nav-text>数据结构</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E4%B8%BA%E4%BA%86%E8%A7%A3%E6%9E%90%E6%96%B9%E4%BE%BF%E8%80%8C%E5%AE%9A%E4%B9%89%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84><span class=nav-number>3.1.</span> <span class=nav-text>为了解析方便而定义的数据结构</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84><span class=nav-number>3.2.</span> <span class=nav-text>网络结构的数据结构</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%85%B6%E4%BB%96%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84><span class=nav-number>3.3.</span> <span class=nav-text>其他类型的数据结构</span></a></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E6%80%BB%E7%BB%93><span class=nav-number>4.</span> <span class=nav-text>总结</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#%E5%A3%B0%E6%98%8E><span class=nav-number>5.</span> <span class=nav-text>声明</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#reference><span class=nav-number>6.</span> <span class=nav-text>Reference</span></a></ol></div></div></section><!--/noindex--></div></aside></div></main><footer class=footer id=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2022</span><span class=with-love> <i class="fa fa-user"></i> </span><span class=author itemprop=copyrightHolder>FesianXu</span></div><div class=“theme-info”><div class=“powered-by”></div><span class=“post-count”> 该站点文章共173.2k字，欢迎光临~ </span></div><script async src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><div class=busuanzi-count><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv> <i class="fa fa-user"></i> <span class=busuanzi-value id=busuanzi_value_site_uv></span> </span><span class=site-pv> <i class="fa fa-eye"></i> <span class=busuanzi-value id=busuanzi_value_site_pv></span> </span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i></div></div><script>if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }</script><script src=/lib/jquery/index.js></script><script src=/lib/fastclick/lib/fastclick.min.js></script><script src=/lib/jquery_lazyload/jquery.lazyload.js></script><script src=/lib/velocity/velocity.min.js></script><script src=/lib/velocity/velocity.ui.min.js></script><script src=/lib/fancybox/source/jquery.fancybox.pack.js></script><script src=/js/src/utils.js></script><script src=/js/src/motion.js></script><script src=/js/src/scrollspy.js></script><script src=/js/src/post-details.js></script><script src=/js/src/bootstrap.js></script><script>// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script src=/live2dw/lib/L2Dwidget.min.js></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script>