<!doctypehtml><html class="theme-next muse use-motion" lang=zh-CN><meta charset=UTF-8><meta content=IE=edge http-equiv=X-UA-Compatible><meta content=width=device-width,initial-scale=1,maximum-scale=1 name=viewport><meta content=#222 name=theme-color><meta content=no-transform http-equiv=Cache-Control><meta content=no-siteapp http-equiv=Cache-Control><link href=/lib/fancybox/source/jquery.fancybox.css?v=2.1.5 rel=stylesheet><link href=/lib/font-awesome/css/font-awesome.min.css?v=4.6.2 rel=stylesheet><link href=/css/main.css?v=5.1.4 rel=stylesheet><link href=/images/apple-touch-icon-next.png?v=5.1.4 rel=apple-touch-icon sizes=180x180><link href=/images/favicon-32x32-next.png?v=5.1.4 rel=icon sizes=32x32 type=image/png><link href=/images/favicon-16x16-next.png?v=5.1.4 rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg?v=5.1.4 rel=mask-icon><meta content=并行数据加载,数据数据读取, name=keywords><meta content=在TensorFlow中自带有queue和TFrecord以用为异步并行加载数据，以提高整体系统的性能，但是有些情况下，并不需要或者不能用TFrecord，这个时候，可以手动写一个简单的并行加载数据的框架，可以大大提高系统的性能。 name=description><meta content=article property=og:type><meta content=如何在TensorFlow中使用并行数据加载，解决视频读取问题 property=og:title><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/index.html property=og:url><meta content=机器学习杂货铺总店 property=og:site_name><meta content=在TensorFlow中自带有queue和TFrecord以用为异步并行加载数据，以提高整体系统的性能，但是有些情况下，并不需要或者不能用TFrecord，这个时候，可以手动写一个简单的并行加载数据的框架，可以大大提高系统的性能。 property=og:description><meta content=zh_CN property=og:locale><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/qrcode.png property=og:image><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/img/serial_model.png property=og:image><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/img/parallel_model.png property=og:image><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/img/s_res.png property=og:image><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/img/p_res.png property=og:image><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/img/p_res_2.png property=og:image><meta content=2023-01-30T04:16:39.000Z property=article:published_time><meta content=2023-01-30T04:20:04.051Z property=article:modified_time><meta content=FesianXu property=article:author><meta content=并行数据加载 property=article:tag><meta content=数据数据读取 property=article:tag><meta content=summary name=twitter:card><meta content=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/qrcode.png name=twitter:image><script id=hexo.configurations>var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };</script><link href=https://FesianXu.github.io/2023/01/30/tf-parallel-data-loading-20230130/ rel=canonical><title>如何在TensorFlow中使用并行数据加载，解决视频读取问题 | 机器学习杂货铺总店</title><meta content="Hexo 5.4.2" name=generator><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}</style><body itemscope itemtype=http://schema.org/WebPage lang=zh-CN><div class="container sidebar-position-left page-post-detail"><div class=headband></div><header class=header id=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-wrapper><div class=site-meta><div class=custom-logo-site-title><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <span class=site-title>机器学习杂货铺总店</span> <span class=logo-line-after><i></i></span> </a></div><p class=site-subtitle></div><div class=site-nav-toggle><button><span class=btn-bar></span> <span class=btn-bar></span> <span class=btn-bar></span></button></div></div><nav class=site-nav><ul class=menu id=menu><li class="menu-item menu-item-home"><a href=/ rel=section> <i class="menu-item-icon fa fa-fw fa-home"></i> <br> Home </a><li class="menu-item menu-item-about"><a href=/about/ rel=section> <i class="menu-item-icon fa fa-fw fa-user"></i> <br> About </a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section> <i class="menu-item-icon fa fa-fw fa-tags"></i> <br> Tags </a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section> <i class="menu-item-icon fa fa-fw fa-th"></i> <br> Categories </a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section> <i class="menu-item-icon fa fa-fw fa-archive"></i> <br> Archives </a><li class="menu-item menu-item-search"><a class=popup-trigger href=javascript:;> <i class="menu-item-icon fa fa-search fa-fw"></i> <br> Search </a></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon> <i class="fa fa-search"></i> </span><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span><div class=local-search-input-wrapper><input autocomplete=off id=local-search-input placeholder=Searching... spellcheck=false></div></div><div id=local-search-result></div></div></div></nav></div></header><main class=main id=main><div class=main-inner><div class=content-wrap><div class=content id=content><div class=posts-expand id=posts><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><div class=post-block><link href=https://FesianXu.github.io/2023/01/30/tf-parallel-data-loading-20230130/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta itemprop=name> <meta itemprop=description> <meta content=/%5Bobject%20Object%5D itemprop=image> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=机器学习杂货铺总店 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>如何在TensorFlow中使用并行数据加载，解决视频读取问题</h1><div class=post-meta><span class=post-time> <span class=post-meta-item-icon> <i class="fa fa-calendar-o"></i> </span> <span class=post-meta-item-text>Posted on</span> <time itemprop="dateCreated datePublished" title="Post created" datetime=2023-01-30T12:16:39+08:00> 2023-01-30 </time> </span><span class=post-category> <span class=post-meta-divider>|</span> <span class=post-meta-item-icon> <i class="fa fa-folder-o"></i> </span> <span class=post-meta-item-text>In</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/TensorFlow/ itemprop=url rel=index> <span itemprop=name>TensorFlow</span> </a> </span> </span><span class=post-meta-divider>|</span><span class=page-pv><i class="fa fa-file-o"></i> <span class=busuanzi-value id=busuanzi_value_page_pv></span> </span><div class=post-wordcount><span class=post-meta-item-icon> <i class="fa fa-file-word-o"></i> </span><span class=post-meta-item-text>Words count in article:</span><span title="Words count in article"> 1.7k 字 </span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-clock-o"></i> </span><span class=post-meta-item-text>Reading time ≈</span><span title="Reading time"> 6 分钟 </span></div></div></header><div class=post-body itemprop=articleBody><p>在TensorFlow中自带有queue和TFrecord以用为异步并行加载数据，以提高整体系统的性能，但是有些情况下，并不需要或者不能用TFrecord，这个时候，可以手动写一个简单的并行加载数据的框架，可以大大提高系统的性能。 <span id=more></span><h2 id=前言>前言</h2><p>在TensorFlow中自带有queue和TFrecord以用为异步并行加载数据，以提高整体系统的性能，但是有些情况下，并不需要或者不能用TFrecord，这个时候，可以手动写一个简单的并行加载数据的框架，可以大大提高系统的性能。<p><strong>如有谬误，请联系指正。转载请注明出处。</strong><p><span class="math inline"><mjx-container class=MathJax jax=SVG><svg style="vertical-align: -0.075ex;" viewbox="0 -683 833 716" focusable=false height=1.62ex role=img width=1.885ex xmlns=http://www.w3.org/2000/svg><g fill=currentColor stroke=currentColor stroke-width=0 transform=scale(1,-1)><g data-mml-node=math><g data-mml-node=mi><path d="M46 676Q46 679 51 683H781Q786 679 786 676Q786 674 617 326T444 -26Q439 -33 416 -33T388 -26Q385 -22 216 326T46 676ZM697 596Q697 597 445 597T193 596Q195 591 319 336T445 80L697 596Z" data-c=2207 /></g></g></g></svg></mjx-container></span> 联系方式：<p><strong>e-mail</strong>: FesianXu@gmail.com<p><strong>github</strong>: https://github.com/FesianXu<p><strong>code</strong>: https://github.com/FesianXu/Parallel-DataLoader-in-TensorFlow<p><strong>知乎专栏</strong>: <a href=https://zhuanlan.zhihu.com/c_1265262560611299328 rel=noopener target=_blank>计算机视觉/计算机图形理论与应用</a><p><strong>微信公众号</strong>：<p><img src=/2023/01/30/tf-parallel-data-loading-20230130/qrcode.png><hr><h1 id=为什么需要并行数据加载>为什么需要并行数据加载</h1><p>在很多深度学习应用中，特别是涉及到图片甚至是视频的处理的时候，经常需要解码图片和视频格式以将其加载到内存中去，本文以解码avi视频为例子，这个过程通常是很慢的，有时候解码一个批次的视频（如128个视频）甚至会需要3秒钟，相比而言，在GPU比如GTX 1080Ti中对模型进行训练反而不需要那么久，如果采取读一个批次的视频，然后再进行训练这种串行的训练策略，那么整个系统的瓶颈将会受限于整个系统的IO能力和解码能力，倒反而不是网络训练了，这样就有本末倒置之嫌了。解决视频解码慢也可以通过预先将视频解码为图片，然后在训练的过程中读取图片，这会省去解码视频的时间，但是这样大大增大了对硬盘的需求。以前我做过一个实验，6400个avi视频，总大小约为4GB，经过预解码为图片后，体积增加了约10倍！可想而知，如果这个视频量更大，硬盘是很难承受的（比如NTU RGB-D数据集有约50000个RGB高清视频）。于是，<strong>这个时候，我们可以考虑并行地加载数据，解码视频。</strong><h1 id=系统模型>系统模型</h1><p>接下来我们的讨论将基于假设：<ol type=1><li>我们的网络训练是在高性能GPU上完成的，视频解码是在CPU上完成的，于是单次数据读取时间大于单次网络训练时间，既是<span class="math inline"><mjx-container class=MathJax jax=SVG><svg style="vertical-align: -0.72ex;" viewbox="0 -626 7878.4 944.2" focusable=false height=2.136ex role=img width=17.824ex xmlns=http://www.w3.org/2000/svg><g fill=currentColor stroke=currentColor stroke-width=0 transform=scale(1,-1)><g data-mml-node=math><g data-mml-node=msub><g data-mml-node=mi><path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" data-c=1D461 /></g><g transform="translate(394,-176.7) scale(0.707)" data-mjx-texclass=ORD data-mml-node=TeXAtom><g data-mml-node=mi><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>网</text></g><g data-mml-node=mi transform=translate(1000,0)><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>络</text></g><g data-mml-node=mi transform=translate(2000,0)><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>训</text></g><g data-mml-node=mi transform=translate(3000,0)><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>练</text></g></g></g><g data-mml-node=mo transform=translate(3550.2,0)><path d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" data-c=3C /></g><g data-mml-node=msub transform=translate(4606,0)><g data-mml-node=mi><path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" data-c=1D461 /></g><g transform="translate(394,-176.7) scale(0.707)" data-mjx-texclass=ORD data-mml-node=TeXAtom><g data-mml-node=mi><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>数</text></g><g data-mml-node=mi transform=translate(1000,0)><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>据</text></g><g data-mml-node=mi transform=translate(2000,0)><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>加</text></g><g data-mml-node=mi transform=translate(3000,0)><text data-variant=normal font-family=serif font-size=884px transform=scale(1,-1)>载</text></g></g></g></g></g></svg></mjx-container></span><li>称数据加载为生产者，网络训练为消费者。</ol><h2 id=串行的数据加载模型>串行的数据加载模型</h2><p><img src=/2023/01/30/tf-parallel-data-loading-20230130/img/serial_model.png><p>串行数据加载如上图描述，数据加载的工作在CPU上完成，网络训练在GPU上完成，这个时候，很容易观察到在数据加载的时候，GPU是空闲的，而在GPU训练的时候，CPU又是空闲的，因此无论是CPU还是GPU都没有得到充分利用。<h2 id=并行的数据加载模型>并行的数据加载模型</h2><p><img src=/2023/01/30/tf-parallel-data-loading-20230130/img/parallel_model.png><p>并行数据加载模型如上图所示，在这个模型中，我们首先需要维护一个全局的FIFO队列，这个队列用于保存视频解码过程中的每一个批次，同时需要产生多个DataLoader线程用于解码数据和将数据入队，最后需要一个主线程，用于模型训练同时负责数据出队。当全局队列为空的时候，出队和计算线程将会被阻塞，直到数据加载线程将数据入队后为止；当全局队列为慢的时候，入队和解码线程将会被阻塞，直到计算线程出队使用了数据为止。这样就构成了一个并行数据加载的模型了。<h1 id=实现>实现</h1><p>整个过程可以在python中简单实现，我们需要定义一个FIFOqueue类，用于保存数据，如：<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> queue</span><br><span class=line><span class=keyword>class</span> <span class="title class_">FIFOQueue</span>(<span class="title class_ inherited__">object</span>):</span><br><span class=line>  __max_len = <span class=literal>None</span></span><br><span class=line>  __queue = <span class=literal>None</span></span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">__init__</span>(<span class=params>self, max_len=<span class=number>5</span></span>):</span><br><span class=line>    <span class=keyword>if</span> self.__max_len <span class=keyword>is</span> <span class=literal>None</span>:</span><br><span class=line>      self.__max_len = max_len</span><br><span class=line>    <span class=keyword>else</span>:</span><br><span class=line>      <span class=keyword>if</span> self.__max_len <span class=keyword>is</span> <span class=keyword>not</span> max_len:</span><br><span class=line>        <span class=keyword>raise</span> ValueError(<span class=string>'The FIFOQueue has been declared yet and max_len is not same!'</span>)</span><br><span class=line></span><br><span class=line>    <span class=keyword>if</span> self.__queue <span class=keyword>is</span> <span class=literal>None</span>:</span><br><span class=line>      self.__queue = queue.Queue(maxsize=max_len)</span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">enqueue</span>(<span class=params>self, item</span>):</span><br><span class=line>    <span class=string>'''</span></span><br><span class=line><span class=string>    put a batch into queue. If the queue is full, then it will be blocked and wait until the queue is not full.</span></span><br><span class=line><span class=string>    :param item: a batch with the format of (data_batch, data_label)</span></span><br><span class=line><span class=string>    :return: None</span></span><br><span class=line><span class=string>    '''</span></span><br><span class=line>    self.__queue.put(item)</span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">dequeue</span>(<span class=params>self</span>):</span><br><span class=line>    <span class=string>'''</span></span><br><span class=line><span class=string>    pop a batch from queue. If the queue is empty then it will be blocked till the queue is not empty.</span></span><br><span class=line><span class=string>    :return: the batch with the format of (data_batch, data_label)</span></span><br><span class=line><span class=string>    '''</span></span><br><span class=line>    item = self.__queue.get()</span><br><span class=line>    <span class=keyword>return</span> item</span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">max_len</span>(<span class=params>self</span>):</span><br><span class=line>    <span class=keyword>return</span> self.__max_len</span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">get_len</span>(<span class=params>self</span>):</span><br><span class=line>    <span class=keyword>return</span> self.__queue.qsize()</span><br></pre></table></figure><p>可以发现只是对queue的简单封装。<p>在最主要的<strong>Train类</strong>中，如：<figure class="highlight python"><table><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br><span class=line>25</span><br><span class=line>26</span><br><span class=line>27</span><br><span class=line>28</span><br><span class=line>29</span><br><span class=line>30</span><br><span class=line>31</span><br><span class=line>32</span><br><span class=line>33</span><br><span class=line>34</span><br><span class=line>35</span><br><span class=line>36</span><br><span class=line>37</span><br><span class=line>38</span><br><span class=line>39</span><br><span class=line>40</span><br><span class=line>41</span><br><span class=line>42</span><br><span class=line>43</span><br></pre><td class=code><pre><span class=line><span class=keyword>import</span> FIFOqueue <span class=keyword>as</span> queue</span><br><span class=line><span class=keyword>import</span> threading</span><br><span class=line></span><br><span class=line><span class=keyword>class</span> <span class="title class_">Train</span>(<span class="title class_ inherited__">object</span>):</span><br><span class=line>  _train_global_queue = <span class=literal>None</span></span><br><span class=line>  _val_global_queue = <span class=literal>None</span></span><br><span class=line>  _test_global_queue = <span class=literal>None</span></span><br><span class=line>  _threads = []</span><br><span class=line></span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">__init__</span>(<span class=params>self,</span></span><br><span class=line><span class=params>               main_task,</span></span><br><span class=line><span class=params>               batch_size=<span class=number>32</span>,</span></span><br><span class=line><span class=params>               train_yield=<span class=literal>None</span>,</span></span><br><span class=line><span class=params>               val_yield=<span class=literal>None</span>,</span></span><br><span class=line><span class=params>               test_yield=<span class=literal>None</span>,</span></span><br><span class=line><span class=params>               max_nthread=<span class=number>10</span>,</span></span><br><span class=line><span class=params>               max_len=<span class=number>10</span></span>):</span><br><span class=line>    self._train_global_queue = queue.FIFOQueue(max_len=max_len) <span class=keyword>if</span> train_yield <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span> <span class=keyword>else</span> <span class=literal>None</span></span><br><span class=line>    self._val_global_queue = queue.FIFOQueue(max_len=max_len) <span class=keyword>if</span> val_yield <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span> <span class=keyword>else</span> <span class=literal>None</span></span><br><span class=line>    self._test_global_queue = queue.FIFOQueue(max_len=max_len) <span class=keyword>if</span> test_yield <span class=keyword>is</span> <span class=keyword>not</span> <span class=literal>None</span> <span class=keyword>else</span> <span class=literal>None</span></span><br><span class=line>    <span class=comment># init the global queue and maintain them</span></span><br><span class=line>    train_threads = [threading.Thread(target=self._data_enqueue,</span><br><span class=line>                     args=(train_yield, batch_size, task_id, <span class=string>'train_data_load'</span>, self._train_global_queue))</span><br><span class=line>    <span class=keyword>for</span> task_id <span class=keyword>in</span> <span class=built_in>range</span>(max_nthread)]</span><br><span class=line></span><br><span class=line>    <span class=keyword>def</span> <span class="title function_">wrapper_main_task</span>(<span class=params>fn</span>):</span><br><span class=line>      <span class=keyword>while</span> <span class=literal>True</span>:</span><br><span class=line>        fn(self._train_global_queue.dequeue())</span><br><span class=line></span><br><span class=line>    self._threads += train_threads</span><br><span class=line>    self._threads += [threading.Thread(target=wrapper_main_task, args=([main_task]))]</span><br><span class=line></span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">_data_enqueue</span>(<span class=params>self, fn, batch_size, task_id, task_type, queue_h</span>):</span><br><span class=line>    <span class=built_in>print</span>(<span class=string>'here begin the data loading with task_id %d with type %s'</span> % (task_id, task_type))</span><br><span class=line>    <span class=keyword>while</span> <span class=literal>True</span>:</span><br><span class=line>      item = fn()</span><br><span class=line>      item[<span class=string>'task_id'</span>] = task_id</span><br><span class=line>      item[<span class=string>'task_type'</span>] = task_type</span><br><span class=line>      queue_h.enqueue(item=item)</span><br><span class=line></span><br><span class=line>  <span class=keyword>def</span> <span class="title function_">start</span>(<span class=params>self</span>):</span><br><span class=line>    <span class=keyword>for</span> each_t <span class=keyword>in</span> self._threads:</span><br><span class=line>      each_t.start()</span><br></pre></table></figure><p>我们实现了刚才说是的并行加载的过程，其中需要注意几点：<ol type=1><li><code>_data_enqueue</code>是用于将数据入队列的，其中<code>fn</code>为数据生成器，需要用户自行重写传入。<li><code>wrapper_main_task</code>是用于封装主任务的，并且在使得可以在主任务中出队，利用数据。</ol><p>具体的使用过程请参考github上的代码，我已经开源到github上了。<h1 id=实验效果>实验效果</h1><p>在符合我们的假设的情况下，我们利用<code>time.sleep</code>对生产者和消费者进行模拟，其中消费者延时0.2秒，生产者延时1秒。（在生产者中还进行了简单的文本读取，作为实际例子。）<p>可以观察到在单线程的时候其cpu使用率仅为5.3%，在实际print中看到也是数据生成的很慢：<p><img src=/2023/01/30/tf-parallel-data-loading-20230130/img/s_res.png><p>而在开了10个生产者线程之后，cpu使用率变为29.8%，提高了接近6倍。<p><img src=/2023/01/30/tf-parallel-data-loading-20230130/img/p_res.png><p>在开了30个生产者线程之后，cpu使用率变为119.3%提高了20多倍。<p><img src=/2023/01/30/tf-parallel-data-loading-20230130/img/p_res_2.png><p>当然也不是说开越多生产者越好，这个是与具体的任务有关的，但是只要是符合基本假设，都可以有较大幅度的系统提升。</div><div><ul class=post-copyright><li class=post-copyright-author><strong>Post author:</strong> FesianXu<li class=post-copyright-link><strong>Post link:</strong> <a href=https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/ title=如何在TensorFlow中使用并行数据加载，解决视频读取问题>https://fesianxu.github.io/2023/01/30/tf-parallel-data-loading-20230130/</a><li class=post-copyright-license><strong>Copyright Notice: </strong> All articles in this blog are licensed under <a rel="external nofollow" href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank>CC BY-NC-SA 3.0</a> unless stating additionally.</ul></div><footer class=post-footer><div class=post-tags><a href=/tags/%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/ rel=tag># 并行数据加载</a><a href=/tags/%E6%95%B0%E6%8D%AE%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96/ rel=tag># 数据数据读取</a></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/2023/01/30/tf-load-numpy-saved-ckpt-20230130/ rel=next title=利用numpy数组保存TensorFlow模型的参数> <i class="fa fa-chevron-left"></i> 利用numpy数组保存TensorFlow模型的参数 </a></div><span class=post-nav-divider></span><div class="post-nav-prev post-nav-item"><a href=/2023/01/30/deconv-20230130/ rel=prev title=一文搞懂反卷积，转置卷积> 一文搞懂反卷积，转置卷积 <i class="fa fa-chevron-right"></i> </a></div></div></footer></div></article><div class=post-spread></div></div></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside class=sidebar id=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>Table of Contents<li class=sidebar-nav-overview data-target=site-overview-wrap>Overview</ul><section class="site-overview-wrap sidebar-panel"><div class=site-overview><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt class=site-author-image itemprop=image src=/%5Bobject%20Object%5D><p class=site-author-name itemprop=name><p class="site-description motion-element" itemprop=description></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/archives/%7C%7C%20archive> <span class=site-state-item-count>79</span> <span class=site-state-item-name>posts</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/index.html> <span class=site-state-item-count>23</span> <span class=site-state-item-name>categories</span> </a></div><div class="site-state-item site-state-tags"><a href=/tags/index.html> <span class=site-state-item-count>130</span> <span class=site-state-item-name>tags</span> </a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item> <a href=https://github.com/FesianXu target=_blank title=GitHub> <i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class=links-of-author-item> <a href=mailto:FesianXu@gmail.com target=_blank title=E-Mail> <i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class=links-of-author-item> <a href=https://stackoverflow.com/users/7348519/fesianxu target=_blank title=StackOverflow> <i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a> </span></div></div></section><!--noindex--><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%89%8D%E8%A8%80><span class=nav-number>1.</span> <span class=nav-text>前言</span></a></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%B9%B6%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD><span class=nav-number></span> <span class=nav-text>为什么需要并行数据加载</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B><span class=nav-number></span> <span class=nav-text>系统模型</span></a><ol class=nav-child><li class="nav-item nav-level-2"><a class=nav-link href=#%E4%B8%B2%E8%A1%8C%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B><span class=nav-number>1.</span> <span class=nav-text>串行的数据加载模型</span></a><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%B9%B6%E8%A1%8C%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B><span class=nav-number>2.</span> <span class=nav-text>并行的数据加载模型</span></a></ol><li class="nav-item nav-level-1"><a class=nav-link href=#%E5%AE%9E%E7%8E%B0><span class=nav-number></span> <span class=nav-text>实现</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#%E5%AE%9E%E9%AA%8C%E6%95%88%E6%9E%9C><span class=nav-number></span> <span class=nav-text>实验效果</span></a></div></div></section><!--/noindex--></div></aside></div></main><footer class=footer id=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2023</span><span class=with-love> <i class="fa fa-user"></i> </span><span class=author itemprop=copyrightHolder>FesianXu</span></div><div class=“theme-info”><div class=“powered-by”></div><span class=“post-count”> 该站点文章共236.6k字，欢迎光临~ </span></div><script async src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><div class=busuanzi-count><script async src=https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv> <i class="fa fa-user"></i> <span class=busuanzi-value id=busuanzi_value_site_uv></span> </span><span class=site-pv> <i class="fa fa-eye"></i> <span class=busuanzi-value id=busuanzi_value_site_pv></span> </span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i></div></div><script>if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }</script><script src=/lib/jquery/index.js></script><script src=/lib/fastclick/lib/fastclick.min.js></script><script src=/lib/jquery_lazyload/jquery.lazyload.js></script><script src=/lib/velocity/velocity.min.js></script><script src=/lib/velocity/velocity.ui.min.js></script><script src=/lib/fancybox/source/jquery.fancybox.pack.js></script><script src=/js/src/utils.js></script><script src=/js/src/motion.js></script><script src=/js/src/scrollspy.js></script><script src=/js/src/post-details.js></script><script src=/js/src/bootstrap.js></script><script>// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script src=/live2dw/lib/L2Dwidget.min.js></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script>