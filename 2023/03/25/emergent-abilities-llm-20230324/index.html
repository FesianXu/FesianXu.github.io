<!doctypehtml><html class="theme-next muse use-motion" lang=zh-CN><meta charset=UTF-8><meta content=IE=edge http-equiv=X-UA-Compatible><meta content=width=device-width,initial-scale=1,maximum-scale=1 name=viewport><meta content=#222 name=theme-color><meta content=no-transform http-equiv=Cache-Control><meta content=no-siteapp http-equiv=Cache-Control><link href=/lib/fancybox/source/jquery.fancybox.css?v=2.1.5 rel=stylesheet><link href=/lib/font-awesome/css/font-awesome.min.css?v=4.6.2 rel=stylesheet><link href=/css/main.css?v=5.1.4 rel=stylesheet><link href=/images/apple-touch-icon-next.png?v=5.1.4 rel=apple-touch-icon sizes=180x180><link href=/images/favicon-32x32-next.png?v=5.1.4 rel=icon sizes=32x32 type=image/png><link href=/images/favicon-16x16-next.png?v=5.1.4 rel=icon sizes=16x16 type=image/png><link color=#222 href=/images/logo.svg?v=5.1.4 rel=mask-icon><meta content=论文极速读,大模型,语言模型,涌现能力, name=keywords><link href=/atom.xml rel=alternate title=机器学习杂货铺总店 type=application/atom+xml><meta content="最近chatGPT、GPT-4火爆了全网，笔者觉得大规模语言模型（Large Language Model, LLM）可能是未来人工智能发展的方向，因此最近也在恶补相关的论文。本次分享一个经典的工作，该工作介绍了LLM中的一种独特模型属性——“能力涌现”，而这个能力可以说是chatGPT、GPT-4等对话模型的基石..." name=description><meta content=article property=og:type><meta content="【论文极速读】 大规模语言模型中的能力“涌现”现象" property=og:title><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/index.html property=og:url><meta content=机器学习杂货铺总店 property=og:site_name><meta content="最近chatGPT、GPT-4火爆了全网，笔者觉得大规模语言模型（Large Language Model, LLM）可能是未来人工智能发展的方向，因此最近也在恶补相关的论文。本次分享一个经典的工作，该工作介绍了LLM中的一种独特模型属性——“能力涌现”，而这个能力可以说是chatGPT、GPT-4等对话模型的基石..." property=og:description><meta content=zh_CN property=og:locale><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/imgs/qrcode.png property=og:image><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/imgs/model-scale-perf.png property=og:image><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/imgs/fig-few-shot-prompt.png property=og:image><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/imgs/model-scale-specialized-prompt.png property=og:image><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/imgs/tab-many-emergent-abilities.png property=og:image><meta content=2023-03-24T17:10:44.000Z property=article:published_time><meta content=2023-03-24T17:14:46.009Z property=article:modified_time><meta content=FesianXu property=article:author><meta content=论文极速读 property=article:tag><meta content=大模型 property=article:tag><meta content=语言模型 property=article:tag><meta content=涌现能力 property=article:tag><meta content=summary name=twitter:card><meta content=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/imgs/qrcode.png name=twitter:image><script id=hexo.configurations>var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };</script><link href=https://FesianXu.github.io/2023/03/25/emergent-abilities-llm-20230324/ rel=canonical><title>【论文极速读】 大规模语言模型中的能力“涌现”现象 | 机器学习杂货铺总店</title><meta content="Hexo 7.3.0" name=generator><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}</style><body itemscope itemtype=http://schema.org/WebPage lang=zh-CN><div class="container sidebar-position-left page-post-detail"><div class=headband></div><header class=header id=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-wrapper><div class=site-meta><div class=custom-logo-site-title><a class=brand href=/ rel=start> <span class=logo-line-before><i></i></span> <span class=site-title>机器学习杂货铺总店</span> <span class=logo-line-after><i></i></span> </a></div><p class=site-subtitle></div><div class=site-nav-toggle><button><span class=btn-bar></span> <span class=btn-bar></span> <span class=btn-bar></span></button></div></div><nav class=site-nav><ul class=menu id=menu><li class="menu-item menu-item-home"><a href=/ rel=section> <i class="menu-item-icon fa fa-fw fa-home"></i> <br> Home </a><li class="menu-item menu-item-about"><a href=/about/ rel=section> <i class="menu-item-icon fa fa-fw fa-user"></i> <br> About </a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section> <i class="menu-item-icon fa fa-fw fa-tags"></i> <br> Tags </a><li class="menu-item menu-item-categories"><a href=/categories/ rel=section> <i class="menu-item-icon fa fa-fw fa-th"></i> <br> Categories </a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section> <i class="menu-item-icon fa fa-fw fa-archive"></i> <br> Archives </a><li class="menu-item menu-item-search"><a class=popup-trigger href=javascript:;> <i class="menu-item-icon fa fa-search fa-fw"></i> <br> Search </a></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon> <i class="fa fa-search"></i> </span><span class=popup-btn-close> <i class="fa fa-times-circle"></i> </span><div class=local-search-input-wrapper><input autocomplete=off id=local-search-input placeholder=Searching... spellcheck=false></div></div><div id=local-search-result></div></div></div></nav></div></header><main class=main id=main><div class=main-inner><div class=content-wrap><div class=content id=content><div class=posts-expand id=posts><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><div class=post-block><link href=https://FesianXu.github.io/2023/03/25/emergent-abilities-llm-20230324/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta itemprop=name> <meta itemprop=description> <meta content=/%5Bobject%20Object%5D itemprop=image> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=机器学习杂货铺总店 itemprop=name> </span><header class=post-header><h1 itemprop="name headline" class=post-title>【论文极速读】 大规模语言模型中的能力“涌现”现象</h1><div class=post-meta><span class=post-time> <span class=post-meta-item-icon> <i class="fa fa-calendar-o"></i> </span> <span class=post-meta-item-text>Posted on</span> <time itemprop="dateCreated datePublished" title="Post created" datetime=2023-03-25T01:10:44+08:00> 2023-03-25 </time> </span><span class=post-category> <span class=post-meta-divider>|</span> <span class=post-meta-item-icon> <i class="fa fa-folder-o"></i> </span> <span class=post-meta-item-text>In</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/categories/%E5%A4%A7%E8%A7%84%E6%A8%A1%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ itemprop=url rel=index> <span itemprop=name>大规模语言模型</span> </a> </span> </span><span class=post-meta-divider>|</span><span class=page-pv><i class="fa fa-file-o"></i> <span class=busuanzi-value id=busuanzi_value_page_pv></span> </span><div class=post-wordcount><span class=post-meta-item-icon> <i class="fa fa-file-word-o"></i> </span><span class=post-meta-item-text>Words count in article:</span><span title="Words count in article"> 6.4k 字 </span><span class=post-meta-divider>|</span><span class=post-meta-item-icon> <i class="fa fa-clock-o"></i> </span><span class=post-meta-item-text>Reading time ≈</span><span title="Reading time"> 21 分钟 分钟 </span></div></div></header><div class=post-body itemprop=articleBody><p>最近chatGPT、GPT-4火爆了全网，笔者觉得大规模语言模型（Large Language Model, LLM）可能是未来人工智能发展的方向，因此最近也在恶补相关的论文。本次分享一个经典的工作，该工作介绍了LLM中的一种独特模型属性——“能力涌现”，而这个能力可以说是chatGPT、GPT-4等对话模型的基石... <span id=more></span><div align=right>FesianXu 20230321 at Baidu Search Team</div><h1 id=前言>前言</h1><p>最近chatGPT、GPT-4火爆了全网，笔者觉得大规模语言模型（Large Language Model, LLM）可能是未来人工智能发展的方向，因此最近也在恶补相关的论文。本次分享一个经典的工作，该工作介绍了LLM中的一种独特模型属性——“能力涌现”，而这个能力可以说是chatGPT、GPT-4等对话模型的基石。笔者刚接触该领域不久，<strong>如有谬误请见谅并联系指出，本文遵守<a href=http://creativecommons.org/licenses/by-sa/4.0/ rel=noopener target=_blank>CC 4.0 BY-SA</a>版权协议，转载请联系作者并注明出处，谢谢</strong>。<p><span class="math inline"><mjx-container class=MathJax jax=SVG><svg style="vertical-align: -0.075ex;" viewbox="0 -683 833 716" focusable=false height=1.62ex role=img width=1.885ex xmlns=http://www.w3.org/2000/svg><g fill=currentColor stroke=currentColor stroke-width=0 transform=scale(1,-1)><g data-mml-node=math><g data-mml-node=mi><path d="M46 676Q46 679 51 683H781Q786 679 786 676Q786 674 617 326T444 -26Q439 -33 416 -33T388 -26Q385 -22 216 326T46 676ZM697 596Q697 597 445 597T193 596Q195 591 319 336T445 80L697 596Z" data-c=2207 /></g></g></g></svg></mjx-container></span> 联系方式：<p><strong>e-mail</strong>: FesianXu@gmail.com<p><strong>github</strong>: https://github.com/FesianXu<p><strong>知乎专栏</strong>: <a href=https://zhuanlan.zhihu.com/c_1265262560611299328 rel=noopener target=_blank>计算机视觉/计算机图形理论与应用</a><p><strong>微信公众号</strong>：机器学习杂货铺3号店<p><img src=/2023/03/25/emergent-abilities-llm-20230324/imgs/qrcode.png><hr><p>在论文[1]中，作者指出在语言模型的模型规模<a class=footnote-ref href=#fn1 id=fnref1 role=doc-noteref><sup>1</sup></a>达到一定程度之后，模型会“涌现”（Emergency）出一些小模型所不具有的能力，这些能力包括但不限于：少样本提示（few-shot prompt）、多步推理能力（Multi-step reasoning）、指令执行（Instruction following）、程序执行（program execution）、模型矫正（model calibration）... <strong>涌现</strong>这个概念借用了一篇名为《More is Different》[2] 的文章中提到的“从量变到质变的过程”：<blockquote><p>涌现，是系统中的量变积累导致了质变的过程。</blockquote><p>这个定义能够帮助我们理解LLM的涌现，但是还不够具体，作者给出了一个更适合于LLM的涌现的定义：<blockquote><p>一个能力如果在小模型中不存在，但是在大模型中却存在，这种能力就是一种涌现。</blockquote><p>注意到，涌现的能力神奇的一点在于，并不是持续提高小模型的规模，就能观察到该能力持续的提升的<a class=footnote-ref href=#fn2 id=fnref2 role=doc-noteref><sup>2</sup></a>，这种能力<strong>只有</strong>在模型的规模达到一定程度后，才能观察到。这个涌现的过程，在指标—模型规模的曲线图上就能很容易发现这个模式，如Fig 1.所示，我们发现在不同的测试集中，只有在模型规模达到了一定的程度后，某种能力才会涌现，这个过程并不是连续的，这意味着并不是对小模型进行简单的少量参数增加就能获得涌现能力。<p><img src=/2023/03/25/emergent-abilities-llm-20230324/imgs/model-scale-perf.png><div align=center><b> Fig 1. 模型在不同测试集上的表现性能与模型规模的曲线图，从中能清楚地观察到，当模型规模达到一定程度后，某种能力（此处是few-shot prompt能力）涌现才会出现。 </b></div><p>我们在简单介绍了涌现这个神奇的现象之后，有必要了解下few-shot prompt这种方法，因为这种方法在LLM中经常使用。few-shot/one-shot prompt和finetune都是会采用人工标注数据，但是两者是截然不同的方法，如Fig 2.所示，one-shot/few-shot prompt的方法会将标注数据作为LLM的输入的一部分，比如Fig 2. (a)中将已有的<strong>人工标注</strong>的Review和Sentiment的信息作为输入的提示，并且在这个提示之后拼接真正需要LLM预测的问题“Review: I love this movie”，并且将Sentiment留白，等待LLM的输出，Fig 2. (b)也是类似的过程。Fig 2.给出的例子都是one-shot prompt，而在few-shot prompt中则会拼接更多的人工标注数据，除此之外和one-shot prompt并没有太多的不同，而zero-shot prompt，则不会提供任何人工标注数据作为拼接，直接输入问题期望得到输出。one-shot prompt/few-shot prompt 这个过程也可以称之为In-Context Learning。<p>这个方法看起来很简单，但是其背后的思想却非常深刻。首先我们考察其和finetune的异同。首先，in-context learning和finetune都是采用人工标注数据的方法，finetune会对模型进行由梯度指引的模型参数更新，而in-context learning这种方法则不需要更新模型参数。这一点在LLM上有着非常大的优势，可想而知，当模型的规模达到了上千亿参数后，即便是模型finetune也需要非常大的代价，而不需要进行模型参数更新的in-context learning此时就显得更为迷人。<p>in-context learning还有更为有趣的地方，当我们采用<code>pretrain -> finetune</code>这种范式进行下游任务迁移的时候，我们需要对不同的下游任务进行finetune，通用性有限。而如果我们采用<code>pretrain -> prompt</code>的范式进行下游任务的迁移，则只需要设计不同的prompt就可以了，不需要对预训练后的模型进行干涉，通用性大大增强。那么读者可能就会有疑问，简单地通过修改提示词，即便把若干个人工标注样本拼接上去，就能从LLM中获得我们预想中的输出吗？难道LLM真的是万能的？的确，一般的LM在few-shot prompt中只有接近随机的表现，但是一旦模型的规模达到一定程度，非常神奇的，few-shot prompt的能力就涌现出来了。如Fig 1.所示，我们发现一旦语言模型的规模超过10B（百亿参数），few-shot prompt的性能表现将得到极大幅度的跳跃，这种跳跃式的曲线违背了我们之前对于模型规模和性能之间关系的经验。<p><img src=/2023/03/25/emergent-abilities-llm-20230324/imgs/fig-few-shot-prompt.png><div align=center><b> Fig 2. 采用few-shot prompt的方法使用LLM模型。 </b></div><p>few-shot prompt能力并不是唯一在LLM中涌现出来的能力，如Fig 3.所示，作者还探索了一些其他在LLM能够涌现的能力。<ol type=1><li>多步推理（Multi-step reasoning）：多步推理能力能将一个较复杂问题拆解为多个较简单的步骤进行求解，这个能力是通过一种称之为Chain-of-thought prompting（思维链提示）的技术实现的。如Fig 3. (A)所示，只有在模型规模超过了10B之后，采用了CoT prompt技术的方法开始大幅度超越不采用CoT prompt的方法。<li>指令拆解（Instruction Following）：指令拆解能力在只提供对某个任务的粗糙描述的时候（比如“将匹萨放进冰箱”），语言模型能对这个任务进行具体的拆解与执行（比如将上面的任务拆解为：首先将匹萨打包，然后打开冰箱，最后将匹萨放进空位，关闭冰箱）。如Fig 3. (B)所示，在模型规模大于10B的时候，LLM的指令拆解能力出现了涌现。<li>程序执行（Program Execution）：一些计算型任务需要将整个计算任务拆解为多步的计算过程，比如一个大数加法或者一个程序执行过程，可以拆解为多步简单计算或者程序，如Fig 3. (C)所示，作者呈现了8位数字加法这个任务，在LLM中通过ScratchPad（草稿本，可以理解为将复杂运算拆解为若干简单计算的叠加？），在模型达到100M以后，能够显著超越不采用Scratchpad的方法，因此也是一种能力涌现。<li>模型校准（Model Calibration）：语言模型研究中还有一种能力称之为“校准”，指的是判断模型是否能够预测自身知道如何回答某个问题。有点拗口，其实就是需要让模型对自己不知道如何回答的问题进行拒绝，这个能力在chatGPT上是存在的。如Fig 3. (D)所示，在模型规模达到52B以上的时候，这个能力才有可能涌现。</ol><p><img src=/2023/03/25/emergent-abilities-llm-20230324/imgs/model-scale-specialized-prompt.png><div align=center><b> Fig 3. 大模型涌现的其他能力。 </b></div><p>除了以上提到的大模型涌现能力外，文章还列举了一些其他涌现现象以及对应的模型规模，如Fig 4.所示，不难发现，大部分的涌现能力都要求模型规模足够大，起码需要10B以上。<p><img src=/2023/03/25/emergent-abilities-llm-20230324/imgs/tab-many-emergent-abilities.png><div align=center><b> Fig 4. 大模型的其他涌现能力与其模型规模。 </b></div><h1 id=reference>Reference</h1><p>[1]. Wei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama et al. "Emergent abilities of large language models." <em>arXiv preprint arXiv:2206.07682</em> (2022).<p>[2]. Philip W. Anderson. More is different: Broken symmetry and the nature of the hierarchical structure of science. Science, 177(4047):393–396, 1972. URL http://www.lanais.famaf.unc.edu.ar/cursos/em/Anderson-MoreDifferent-1972.pdf.<section class="footnotes footnotes-end-of-document" id=footnotes role=doc-endnotes><hr><ol><li id=fn1><p>通常指的是模型的参数量，由于计算量和参数量通常有着正相关关系，也可以用FLOPs进行表示模型规模。<a class=footnote-back href=#fnref1 role=doc-backlink>↩︎</a><li id=fn2><p>持续提高模型的规模，从而观察到模型的表现提升，我们将这个过程称之为<strong>规模法则 (scaling law)</strong>。<a class=footnote-back href=#fnref2 role=doc-backlink>↩︎</a></ol></section></div><div><ul class=post-copyright><li class=post-copyright-author><strong>Post author:</strong> FesianXu<li class=post-copyright-link><strong>Post link:</strong> <a title="【论文极速读】 大规模语言模型中的能力“涌现”现象" href=https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/>https://fesianxu.github.io/2023/03/25/emergent-abilities-llm-20230324/</a><li class=post-copyright-license><strong>Copyright Notice: </strong> All articles in this blog are licensed under <a rel="external nofollow" href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank>CC BY-NC-SA 3.0</a> unless stating additionally.</ul></div><footer class=post-footer><div class=post-tags><a href=/tags/%E8%AE%BA%E6%96%87%E6%9E%81%E9%80%9F%E8%AF%BB/ rel=tag># 论文极速读</a><a href=/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/ rel=tag># 大模型</a><a href=/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/ rel=tag># 语言模型</a><a href=/tags/%E6%B6%8C%E7%8E%B0%E8%83%BD%E5%8A%9B/ rel=tag># 涌现能力</a></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/2023/03/04/story-of-multimodal-models-20230304/ rel=next title=视频与图片检索中的多模态语义匹配模型：原理、启示、应用与展望> <i class="fa fa-chevron-left"></i> 视频与图片检索中的多模态语义匹配模型：原理、启示、应用与展望 </a></div><span class=post-nav-divider></span><div class="post-nav-prev post-nav-item"><a title="【论文极速读】将Transformer用在图片上：Vision Transformer论文杂谈" href=/2023/03/25/vit-paper-reading-20230324/ rel=prev> 【论文极速读】将Transformer用在图片上：Vision Transformer论文杂谈 <i class="fa fa-chevron-right"></i> </a></div></div></footer></div></article><div class=post-spread></div></div></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside class=sidebar id=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>Table of Contents<li class=sidebar-nav-overview data-target=site-overview-wrap>Overview</ul><section class="site-overview-wrap sidebar-panel"><div class=site-overview><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img alt class=site-author-image itemprop=image src=/%5Bobject%20Object%5D><p class=site-author-name itemprop=name><p class="site-description motion-element" itemprop=description></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/archives/%7C%7C%20archive> <span class=site-state-item-count>125</span> <span class=site-state-item-name>posts</span> </a></div><div class="site-state-item site-state-categories"><a href=/categories/index.html> <span class=site-state-item-count>40</span> <span class=site-state-item-name>categories</span> </a></div><div class="site-state-item site-state-tags"><a href=/tags/index.html> <span class=site-state-item-count>223</span> <span class=site-state-item-name>tags</span> </a></div></nav><div class="feed-link motion-element"><a href=/atom.xml rel=alternate> <i class="fa fa-rss"></i> RSS </a></div><div class="links-of-author motion-element"><span class=links-of-author-item> <a href=https://github.com/FesianXu target=_blank title=GitHub> <i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class=links-of-author-item> <a href=mailto:FesianXu@gmail.com target=_blank title=E-Mail> <i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class=links-of-author-item> <a href=https://stackoverflow.com/users/7348519/fesianxu target=_blank title=StackOverflow> <i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a> </span></div></div></section><!--noindex--><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><ol class=nav><li class="nav-item nav-level-1"><a class=nav-link href=#%E5%89%8D%E8%A8%80><span class=nav-number>1.</span> <span class=nav-text>前言</span></a><li class="nav-item nav-level-1"><a class=nav-link href=#reference><span class=nav-number>2.</span> <span class=nav-text>Reference</span></a></ol></div></div></section><!--/noindex--></div></aside></div></main><footer class=footer id=footer><div class=footer-inner><div class=copyright>© <span itemprop=copyrightYear>2026</span><span class=with-love> <i class="fa fa-user"></i> </span><span class=author itemprop=copyrightHolder>FesianXu</span></div><div class=“theme-info”><div class=“powered-by”></div><span class=“post-count”> 该站点文章共461k字，欢迎光临~ </span></div><script async src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><div class=busuanzi-count><script async src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><span class=site-uv> <i class="fa fa-user"></i> <span class=busuanzi-value id=busuanzi_value_site_uv></span> </span><span class=site-pv> <i class="fa fa-eye"></i> <span class=busuanzi-value id=busuanzi_value_site_pv></span> </span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i></div></div><script>if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }</script><script src=/lib/jquery/index.js></script><script src=/lib/fastclick/lib/fastclick.min.js></script><script src=/lib/jquery_lazyload/jquery.lazyload.js></script><script src=/lib/velocity/velocity.min.js></script><script src=/lib/velocity/velocity.ui.min.js></script><script src=/lib/fancybox/source/jquery.fancybox.pack.js></script><script src=/js/src/utils.js></script><script src=/js/src/motion.js></script><script src=/js/src/scrollspy.js></script><script src=/js/src/post-details.js></script><script src=/js/src/bootstrap.js></script><script>// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script src=/live2dw/lib/L2Dwidget.min.js></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script>